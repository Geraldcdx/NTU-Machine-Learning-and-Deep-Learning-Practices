{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 4. Classifying Surnames with a Multilayer Perceptron"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from argparse import Namespace\n",
    "from collections import Counter\n",
    "import json\n",
    "import os\n",
    "import string\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Vectorization classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "class Vocabulary(object):\n",
    "    \"\"\"Class to process text and extract vocabulary for mapping\"\"\"\n",
    "\n",
    "    def __init__(self, token_to_idx=None, add_unk=True, unk_token=\"<UNK>\", mask_token=\"<MASK>\"):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            token_to_idx (dict): a pre-existing map of tokens to indices\n",
    "            add_unk (bool): a flag that indicates whether to add the UNK token\n",
    "            unk_token (str): the UNK token to add into the Vocabulary\n",
    "        \"\"\"\n",
    "\n",
    "        if token_to_idx is None:\n",
    "            token_to_idx = {}\n",
    "        self._token_to_idx = token_to_idx         # _token_to_idx: {''@'':0, 'a':1, 'b':2, ....., 'Á': 76}\n",
    "                                                  # _idx_to_token: {0:''@'', 1:'a', 2:'b', ....., 76:'Á'}\n",
    "            \n",
    "                                                  # _token_to_idx: {'Arabic': 0, 'Chinese': 1, ..., 'Vietnamese': 17}\n",
    "                                                  # _idx_to_token: {0:'Arabic',  1:'Chinese', ...,  17:'Vietnamese'}\n",
    "  \n",
    "        self._idx_to_token = {idx: token\n",
    "                              for token, idx in self._token_to_idx.items()}\n",
    "        self._mask_token = mask_token\n",
    "        self._add_unk = add_unk\n",
    "        self._unk_token = unk_token\n",
    "        \n",
    "        \n",
    "        self.unk_index = -1\n",
    "        if add_unk:\n",
    "            self.unk_index = self.add_token(unk_token) \n",
    "            self.mask_index = self.add_token(self._mask_token)  # mask_index set to 0\n",
    "               \n",
    "    def add_token(self, token):\n",
    "        \"\"\"Update mapping dicts based on the token.\n",
    "\n",
    "        Args:\n",
    "            token (str): the item to add into the Vocabulary\n",
    "        Returns:\n",
    "            index (int): the integer corresponding to the token\n",
    "        \"\"\"\n",
    "        token = token\n",
    "        try:\n",
    "            index = self._token_to_idx[token]\n",
    "        except KeyError:\n",
    "            index = len(self._token_to_idx)\n",
    "            self._token_to_idx[token] = index\n",
    "            self._idx_to_token[index] = token\n",
    "        return index\n",
    "    \n",
    "    def lookup_token(self, token):\n",
    "        \"\"\"Retrieve the index associated with the token \n",
    "          or the UNK index if token isn't present.\n",
    "        \n",
    "        Args:\n",
    "            token (str): the token to look up \n",
    "        Returns:\n",
    "            index (int): the index corresponding to the token\n",
    "        Notes:\n",
    "            `unk_index` needs to be >=0 (having been added into the Vocabulary) \n",
    "              for the UNK functionality \n",
    "        \"\"\"\n",
    "        token = token\n",
    "        if self.unk_index >= 0:\n",
    "            return self._token_to_idx.get(token, self.unk_index)\n",
    "        else:\n",
    "            return self._token_to_idx[token]\n",
    "\n",
    "    def lookup_index(self, index):\n",
    "        \"\"\"Return the token associated with the index\n",
    "        \n",
    "        Args: \n",
    "            index (int): the index to look up\n",
    "        Returns:\n",
    "            token (str): the token corresponding to the index\n",
    "        Raises:\n",
    "            KeyError: if the index is not in the Vocabulary\n",
    "        \"\"\"\n",
    "        if index not in self._idx_to_token:\n",
    "            raise KeyError(\"the index (%d) is not in the Vocabulary\" % index)\n",
    "        return self._idx_to_token[index]\n",
    "\n",
    "    def __str__(self):\n",
    "        return \"<Vocabulary(size=%d)>\" % len(self)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self._token_to_idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SurnameVectorizer(object):\n",
    "    \"\"\" The Vectorizer which coordinates the Vocabularies and puts them to use\"\"\"\n",
    "    def __init__(self, surname_vocab, nationality_vocab):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            surname_vocab (Vocabulary): maps characters to integers\n",
    "            nationality_vocab (Vocabulary): maps nationalities to integers\n",
    "        \"\"\"\n",
    "        self.surname_vocab = surname_vocab           # _token_to_idx: {'@':0, 'a':1, 'b':2, ....., 'Á': 76}\n",
    "        self.nationality_vocab = nationality_vocab     # _token_to_idx: {'Arabic': 0, 'Chinese': 1, ..., 'Vietnamese': 17}\n",
    "\n",
    "    def vectorize(self, surname, vector_length=-1):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            surname (str): the surname\n",
    "\n",
    "        Returns:\n",
    "            one_hot (np.ndarray): a collapsed one-hot encoding \n",
    "        \"\"\"\n",
    "        #split the individual characters\n",
    "        indices = [self.surname_vocab.lookup_token(char) for char in surname]\n",
    "        if vector_length < 0:\n",
    "            vector_length = len(indices)\n",
    "        out_vector = np.zeros(vector_length, dtype=np.int64)\n",
    "        out_vector[:len(indices)] = indices     # e.g., \"frankenstein , or the prometheus by mary wolls\" -> [3, 5, 9, 3, .., 35]\n",
    "        out_vector[len(indices):] = self.surname_vocab.mask_index # padding,                                                       # [3, 5, 9, 3, .., 35] -> [3, 5, 9, 3, .., 35, 0, 0, 0, 0]\n",
    "        return out_vector\n",
    "#         vocab = self.surname_vocab\n",
    "#         one_hot = np.zeros(len(vocab), dtype=np.float32)  # in this dataset, vector size is 77.\n",
    "#         for token in surname:\n",
    "#             one_hot[vocab.lookup_token(token)] = 1        # e.g., kim -> [0, 0, 0, 1, 0, 0, 1, 0, 0, 1, ......, 0]\n",
    "#         self.x = one_hot\n",
    "#         return one_hot\n",
    "\n",
    "    @classmethod\n",
    "    def from_dataframe(cls, surname_df):\n",
    "        \"\"\"Instantiate the vectorizer from the dataset dataframe\n",
    "        \n",
    "        Args:\n",
    "            surname_df (pandas.DataFrame): the surnames dataset\n",
    "        Returns:\n",
    "            an instance of the SurnameVectorizer\n",
    "        \"\"\"\n",
    "        surname_vocab = Vocabulary(unk_token=\"@\")\n",
    "        nationality_vocab = Vocabulary(add_unk=False)\n",
    "\n",
    "        for index, row in surname_df.iterrows():\n",
    "            for letter in row.surname:\n",
    "                surname_vocab.add_token(letter)   # token is letter-level.\n",
    "            nationality_vocab.add_token(row.nationality)\n",
    "        \n",
    "        return cls(surname_vocab, nationality_vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SurnameDataset(Dataset):\n",
    "    def __init__(self, surname_df, vectorizer):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            surname_df (pandas.DataFrame): the dataset\n",
    "            vectorizer (SurnameVectorizer): vectorizer instatiated from dataset\n",
    "        \"\"\"\n",
    "        self.surname_df = surname_df\n",
    "        self._vectorizer = vectorizer\n",
    "\n",
    "        measure_len = lambda surname: len(surname)\n",
    "        self._max_seq_length = max(map(measure_len, surname_df.surname))  \n",
    "        \n",
    "        self.train_df = self.surname_df[self.surname_df.split=='train']\n",
    "        self.train_size = len(self.train_df)\n",
    "\n",
    "        self.val_df = self.surname_df[self.surname_df.split=='val']\n",
    "        self.validation_size = len(self.val_df)\n",
    "\n",
    "        self.test_df = self.surname_df[self.surname_df.split=='test']\n",
    "        self.test_size = len(self.test_df)\n",
    "\n",
    "        self._lookup_dict = {'train': (self.train_df, self.train_size),\n",
    "                             'val': (self.val_df, self.validation_size),\n",
    "                             'test': (self.test_df, self.test_size)}\n",
    "\n",
    "        self.set_split('train')\n",
    "        \n",
    "        # Class weights for handling unbalanced data\n",
    "        class_counts = surname_df.nationality.value_counts().to_dict() # {'English': 2972, 'Russian': 2373, ....}\n",
    "        \n",
    "        def sort_key(item):\n",
    "            return self._vectorizer.nationality_vocab.lookup_token(item[0]) # e.g, index of English is 4\n",
    "        sorted_counts = sorted(class_counts.items(), key=sort_key)   # sort by the index number of nationality_vocab\n",
    "                                # {('Arabic', 1603), ('Chinese', 220), ('Czech', 414), ('Dutch', 236),('English', 2972), ...}\n",
    "\n",
    "        frequencies = [count for _, count in sorted_counts]\n",
    "        self.class_weights = 1.0 / torch.tensor(frequencies, dtype=torch.float32) \n",
    "                                                                     # [1/1603, 1/220, 1/414, 1/236, 1/2972, ...]\n",
    "                                                                     # E.g., penalty for Chinese is higher than one for Arabic.\n",
    "    @classmethod\n",
    "    def load_dataset_and_make_vectorizer(cls, surname_csv):\n",
    "        \"\"\"Load dataset and make a new vectorizer from scratch\n",
    "        \n",
    "        Args:\n",
    "            surname_csv (str): location of the dataset\n",
    "        Returns:\n",
    "            an instance of SurnameDataset\n",
    "        \"\"\"\n",
    "        surname_df = pd.read_csv(surname_csv)\n",
    "        train_surname_df = surname_df[surname_df.split=='train']\n",
    "        return cls(surname_df, SurnameVectorizer.from_dataframe(train_surname_df))\n",
    "\n",
    "    def get_vectorizer(self):\n",
    "        \"\"\" returns the vectorizer \"\"\"\n",
    "        return self._vectorizer\n",
    "\n",
    "    def set_split(self, split=\"train\"):\n",
    "        \"\"\" selects the splits in the dataset using a column in the dataframe \"\"\"\n",
    "        self._target_split = split\n",
    "        self._target_df, self._target_size = self._lookup_dict[split]\n",
    "\n",
    "    def __len__(self):\n",
    "        return self._target_size\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"the primary entry point method for PyTorch datasets\n",
    "        \n",
    "        Args:\n",
    "            index (int): the index to the data point \n",
    "        Returns:\n",
    "            a dictionary holding the data point's:\n",
    "                features (x_surname)\n",
    "                label (y_nationality)\n",
    "        \"\"\"\n",
    "        row = self._target_df.iloc[index]\n",
    "\n",
    "        surname_vector = \\\n",
    "            self._vectorizer.vectorize(row.surname, self._max_seq_length)   # e.g., 'kim' -> [0, 0, 0, 1, 0, 0, 1, 0, 0, 1, ......, 0]\n",
    "\n",
    "        nationality_index = \\\n",
    "            self._vectorizer.nationality_vocab.lookup_token(row.nationality)  # e.g., 'Korean' -> 11\n",
    "\n",
    "        return {'x_surname': surname_vector,\n",
    "                'y_nationality': nationality_index}\n",
    "\n",
    "    def get_num_batches(self, batch_size):\n",
    "        \"\"\"Given a batch size, return the number of batches in the dataset\n",
    "        \n",
    "        Args:\n",
    "            batch_size (int)\n",
    "        Returns:\n",
    "            number of batches in the dataset\n",
    "        \"\"\"\n",
    "        return len(self) // batch_size\n",
    "\n",
    "    \n",
    "def generate_batches(dataset, batch_size, shuffle=True,\n",
    "                     drop_last=True, device=\"cpu\"): \n",
    "    \"\"\"\n",
    "    A generator function which wraps the PyTorch DataLoader. It will \n",
    "      ensure each tensor is on the write device location.\n",
    "    \"\"\"\n",
    "    dataloader = DataLoader(dataset=dataset, batch_size=batch_size,\n",
    "                            shuffle=shuffle, drop_last=drop_last)\n",
    "\n",
    "    for data_dict in dataloader: # {'x_surname': [[1,1,..,0,1], [0,0,...,1,0], ...], \n",
    "                                 #  'y_nationality': [4, 5, 10, ..., 14, 4]}\n",
    "        out_data_dict = {}\n",
    "        for name, tensor in data_dict.items():  # name: x_surname & y_nationality\n",
    "            out_data_dict[name] = data_dict[name].to(device)\n",
    "        yield out_data_dict  # return out_data_dict whenever this generator function is called"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Model: SurnameClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SurnameClassifier(nn.Module):\n",
    "    \"\"\" A 2-layer Multilayer Perceptron for classifying surnames \"\"\"\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim, embedding_size, padding_idx=0):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            input_dim (int): the size of the input vectors\n",
    "            hidden_dim (int): the output size of the first Linear layer\n",
    "            output_dim (int): the output size of the second Linear layer\n",
    "        \"\"\"\n",
    "        super(SurnameClassifier, self).__init__()\n",
    "        self.embedding =  nn.Embedding(num_embeddings=input_dim,   \n",
    "                                       embedding_dim=embedding_size,\n",
    "                                       padding_idx=padding_idx)\n",
    "        #hidden_dim = 25\n",
    "        self.fc1 = nn.Linear(in_features=embedding_size,           # Applies a linear transformation to the incoming data\n",
    "                             out_features=hidden_dim, bias = True)\n",
    "        #self.fc1 = nn.Linear(input_dim, hidden_dim)\n",
    "        self.fc2 = nn.Linear(in_features=hidden_dim, out_features = output_dim, bias = True)\n",
    "        #self.fc3 = nn.Linear(in_features=30, out_features = output_dim, bias = True)\n",
    "        \n",
    "        #self.bn1 = nn.BatchNorm1d(hidden_dim) # for batch norm, need to be defined for each layer\n",
    "        #self.bn2 = nn.BatchNorm1d(hidden_dim)\n",
    "        #self.bn3 = nn.BatchNorm1d(output_dim)\n",
    "        #self.dpout = nn.Dropout(p=0.01) # for drop out, p = probability of an element to be zeroed. Default: 0.5\n",
    "\n",
    "\n",
    "    def forward(self, x_in, apply_softmax=False):\n",
    "        \"\"\"The forward pass of the classifier\n",
    "        \n",
    "        Args:\n",
    "            x_in (torch.Tensor): an input data tensor. \n",
    "                x_in.shape should be (batch, input_dim)\n",
    "            apply_softmax (bool): a flag for the softmax activation\n",
    "                should be false if used with the Cross Entropy losses\n",
    "        Returns:\n",
    "            the resulting tensor. tensor.shape should be (batch, output_dim)\n",
    "        \"\"\"\n",
    "        x_embedded =  self.embedding(x_in)\n",
    "        x_embedded_sum = x_embedded.sum(dim=1)\n",
    "        #x_embedded_sum = self.dpout(x_embedded_sum)\n",
    "        x_in = x_embedded_sum\n",
    "        intermediate_vector = self.fc1(x_in)                         # (batch, input_dim) -> (batch, hidden_dim)\n",
    "        #intermediate_vector = self.bn1(intermediate_vector)          # batch norm\n",
    "        m = nn.LeakyReLU(0.1)\n",
    "        #intermediate_vector = self.dpout(intermediate_vector) \n",
    "        intermediate_vector = m(intermediate_vector)   \n",
    "        #intermediate_vector = F.relu(intermediate_vector)            # activation function\n",
    "        #intermediate_vector = self.bn2(intermediate_vector)          # batch norm\n",
    "               # dropout\n",
    "        \n",
    "        prediction_vector = self.fc2(intermediate_vector)\n",
    "        #intermediate_vector = self.bn3(intermediate_vector)          # batch norm\n",
    "        #prediction_vector = self.fc3(intermediate_vector)            # (batch, hidden_dim) -> (batch, output_dim)\n",
    "\n",
    "        if apply_softmax:\n",
    "            prediction_vector = F.softmax(prediction_vector, dim=1)  # (batch, output_dim)\n",
    "\n",
    "        return prediction_vector                                     # (batch, output_dim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Routine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def make_train_state(args):\n",
    "    return {'stop_early': False,\n",
    "            'early_stopping_step': 0,\n",
    "            'early_stopping_best_val': 1e8,\n",
    "            'learning_rate': args.learning_rate,\n",
    "            'epoch_index': 0,\n",
    "            'train_loss': [],\n",
    "            'train_acc': [],\n",
    "            'val_loss': [],\n",
    "            'val_acc': [],\n",
    "            'test_loss': -1,\n",
    "            'test_acc': -1,\n",
    "            'model_filename': args.model_state_file}\n",
    "\n",
    "def update_train_state(args, model, train_state):\n",
    "    \"\"\"Handle the training state updates.\n",
    "\n",
    "    Components:\n",
    "     - Early Stopping: Prevent overfitting.\n",
    "     - Model Checkpoint: Model is saved if the model is better\n",
    "\n",
    "    :param args: main arguments\n",
    "    :param model: model to train\n",
    "    :param train_state: a dictionary representing the training state values\n",
    "    :returns:\n",
    "        a new train_state\n",
    "    \"\"\"\n",
    "\n",
    "    # Save one model at least\n",
    "    if train_state['epoch_index'] == 0:\n",
    "        torch.save(model.state_dict(), train_state['model_filename'])\n",
    "        train_state['stop_early'] = False\n",
    "\n",
    "    # Save model if performance improved\n",
    "    elif train_state['epoch_index'] >= 1:\n",
    "        loss_tm1, loss_t = train_state['val_loss'][-2:]\n",
    "\n",
    "        # If loss worsened\n",
    "        if loss_t >= train_state['early_stopping_best_val']:\n",
    "            # Update step\n",
    "            train_state['early_stopping_step'] += 1\n",
    "        # Loss decreased\n",
    "        else:\n",
    "            # Save the best model\n",
    "            if loss_t < train_state['early_stopping_best_val']:\n",
    "                torch.save(model.state_dict(), train_state['model_filename'])\n",
    "                train_state['early_stopping_best_val'] = loss_t  # update 'early_stopping_best_val'\n",
    "\n",
    "            # Reset early stopping step\n",
    "            train_state['early_stopping_step'] = 0\n",
    "\n",
    "        # Stop early ?\n",
    "        train_state['stop_early'] = \\\n",
    "            train_state['early_stopping_step'] >= args.early_stopping_criteria\n",
    "\n",
    "    return train_state\n",
    "\n",
    "def compute_accuracy(y_pred, y_target):\n",
    "    _, y_pred_indices = y_pred.max(dim=1)\n",
    "    n_correct = torch.eq(y_pred_indices, y_target).sum().item()\n",
    "    return n_correct / len(y_pred_indices) * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### general utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed_everywhere(seed, cuda):\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if cuda:\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "def handle_dirs(dirpath):\n",
    "    if not os.path.exists(dirpath):\n",
    "        os.makedirs(dirpath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Settings and some prep work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expanded filepaths: \n",
      "\tmodel_storage/ch4/surname_mlp\\model.pth\n",
      "Using CUDA: False\n"
     ]
    }
   ],
   "source": [
    "args = Namespace(\n",
    "    # Data and path information\n",
    "    surname_csv=\"data/surnames/surnames_with_splits.csv\",\n",
    "    model_state_file=\"model.pth\",\n",
    "    save_dir=\"model_storage/ch4/surname_mlp\",\n",
    "    # Model hyper parameters\n",
    "    hidden_dim=1000,#300,\n",
    "    embedding_size=200, #was 50\n",
    "    # Training  hyper parameters\n",
    "    seed=1337,\n",
    "    num_epochs=25,#100,\n",
    "    early_stopping_criteria=5,\n",
    "    learning_rate=0.001,\n",
    "    batch_size= 2, #256,#was 64\n",
    "    # Runtime options\n",
    "    cuda=False,\n",
    "    expand_filepaths_to_save_dir=True,\n",
    ")\n",
    "\n",
    "if args.expand_filepaths_to_save_dir:\n",
    "    args.model_state_file = os.path.join(args.save_dir, args.model_state_file)   \n",
    "    print(\"Expanded filepaths: \")\n",
    "    print(\"\\t{}\".format(args.model_state_file))\n",
    "    \n",
    "# Check CUDA\n",
    "if not torch.cuda.is_available():\n",
    "    args.cuda = False\n",
    "\n",
    "args.device = torch.device(\"cuda\" if args.cuda else \"cpu\")\n",
    "    \n",
    "print(\"Using CUDA: {}\".format(args.cuda))\n",
    "\n",
    "\n",
    "# Set seed for reproducibility\n",
    "set_seed_everywhere(args.seed, args.cuda)\n",
    "\n",
    "# handle dirs\n",
    "handle_dirs(args.save_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initializations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating fresh!\n"
     ]
    }
   ],
   "source": [
    "# create dataset and vectorizer\n",
    "print(\"Creating fresh!\")\n",
    "dataset = SurnameDataset.load_dataset_and_make_vectorizer(args.surname_csv)\n",
    "    \n",
    "vectorizer = dataset.get_vectorizer()\n",
    "classifier = SurnameClassifier(input_dim=len(vectorizer.surname_vocab), \n",
    "                               hidden_dim=args.hidden_dim, \n",
    "                               output_dim=len(vectorizer.nationality_vocab),\n",
    "                               embedding_size=args.embedding_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 -> ('', SurnameClassifier(\n",
      "  (embedding): Embedding(80, 200, padding_idx=0)\n",
      "  (fc1): Linear(in_features=200, out_features=1000, bias=True)\n",
      "  (fc2): Linear(in_features=1000, out_features=18, bias=True)\n",
      "))\n",
      "1 -> ('embedding', Embedding(80, 200, padding_idx=0))\n",
      "2 -> ('fc1', Linear(in_features=200, out_features=1000, bias=True))\n",
      "3 -> ('fc2', Linear(in_features=1000, out_features=18, bias=True))\n"
     ]
    }
   ],
   "source": [
    "for idx, m in enumerate(classifier.named_modules()):\n",
    "        print(idx, '->', m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.nn.parameter.Parameter'> torch.Size([80, 200])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([1000, 200])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([1000])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([18, 1000])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([18])\n"
     ]
    }
   ],
   "source": [
    "for param in classifier.parameters():\n",
    "    print(type(param), param.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'@': 0,\n",
       " '<MASK>': 1,\n",
       " 'G': 2,\n",
       " 'a': 3,\n",
       " 'b': 4,\n",
       " 'e': 5,\n",
       " 'r': 6,\n",
       " 'S': 7,\n",
       " 'y': 8,\n",
       " 'g': 9,\n",
       " 'h': 10,\n",
       " 'K': 11,\n",
       " 'o': 12,\n",
       " 'u': 13,\n",
       " 'i': 14,\n",
       " 'I': 15,\n",
       " 's': 16,\n",
       " 'B': 17,\n",
       " 't': 18,\n",
       " 'T': 19,\n",
       " 'n': 20,\n",
       " 'H': 21,\n",
       " 'd': 22,\n",
       " 'A': 23,\n",
       " 'l': 24,\n",
       " 'm': 25,\n",
       " 'M': 26,\n",
       " 'f': 27,\n",
       " 'Z': 28,\n",
       " 'N': 29,\n",
       " 'k': 30,\n",
       " 'w': 31,\n",
       " 'W': 32,\n",
       " 'E': 33,\n",
       " 'c': 34,\n",
       " 'j': 35,\n",
       " 'Q': 36,\n",
       " 'D': 37,\n",
       " 'z': 38,\n",
       " 'F': 39,\n",
       " 'C': 40,\n",
       " 'R': 41,\n",
       " 'Y': 42,\n",
       " 'L': 43,\n",
       " 'J': 44,\n",
       " 'P': 45,\n",
       " 'X': 46,\n",
       " ':': 47,\n",
       " 'O': 48,\n",
       " '-': 49,\n",
       " 'p': 50,\n",
       " 'U': 51,\n",
       " 'v': 52,\n",
       " 'V': 53,\n",
       " '1': 54,\n",
       " 'x': 55,\n",
       " '/': 56,\n",
       " 'q': 57,\n",
       " 'é': 58,\n",
       " 'ê': 59,\n",
       " \"'\": 60,\n",
       " 'É': 61,\n",
       " 'ö': 62,\n",
       " 'ä': 63,\n",
       " 'ü': 64,\n",
       " 'ß': 65,\n",
       " 'ú': 66,\n",
       " 'à': 67,\n",
       " 'ò': 68,\n",
       " 'è': 69,\n",
       " 'ù': 70,\n",
       " 'ó': 71,\n",
       " 'ń': 72,\n",
       " 'Ś': 73,\n",
       " 'ą': 74,\n",
       " 'á': 75,\n",
       " 'Ż': 76,\n",
       " 'ã': 77,\n",
       " 'í': 78,\n",
       " 'ñ': 79}"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.surname_vocab._token_to_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Arabic': 0,\n",
       " 'Chinese': 1,\n",
       " 'Czech': 2,\n",
       " 'Dutch': 3,\n",
       " 'English': 4,\n",
       " 'French': 5,\n",
       " 'German': 6,\n",
       " 'Greek': 7,\n",
       " 'Irish': 8,\n",
       " 'Italian': 9,\n",
       " 'Japanese': 10,\n",
       " 'Korean': 11,\n",
       " 'Polish': 12,\n",
       " 'Portuguese': 13,\n",
       " 'Russian': 14,\n",
       " 'Scottish': 15,\n",
       " 'Spanish': 16,\n",
       " 'Vietnamese': 17}"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.nationality_vocab._token_to_idx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f49a96b447840b48a8583a60791bd14",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='training routine', max=25.0, style=ProgressStyle(descript…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0cfe3d34053f461ca5edea94c4bdb001",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='split=train', max=3840.0, style=ProgressStyle(description…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f7a927a32694803a981b08517861e99",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='split=val', max=820.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "classifier = classifier.to(args.device)\n",
    "dataset.class_weights = dataset.class_weights.to(args.device)\n",
    "\n",
    "    \n",
    "loss_func = nn.CrossEntropyLoss(dataset.class_weights)  # add class_weight for an unbalanced dataset\n",
    "optimizer = optim.Adam(classifier.parameters(), lr=args.learning_rate)\n",
    "#optimizer = optim.Adam(classifier.parameters(), lr=args.learning_rate, weight_decay=0.001) # weight_decay for L2 regularization\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer=optimizer, mode='min', factor=0.1, patience=10) # update learning rate\n",
    "\n",
    "train_state = make_train_state(args)\n",
    "\n",
    "epoch_bar = tqdm(desc='training routine', total=args.num_epochs, position=0)\n",
    "\n",
    "dataset.set_split('train')\n",
    "train_bar = tqdm(desc='split=train', total=dataset.get_num_batches(args.batch_size), position=1, leave=True)\n",
    "dataset.set_split('val')\n",
    "val_bar = tqdm(desc='split=val', total=dataset.get_num_batches(args.batch_size), position=1, leave=True)\n",
    "\n",
    "try:\n",
    "    for epoch_index in range(args.num_epochs):\n",
    "        train_state['epoch_index'] = epoch_index\n",
    "\n",
    "        # Iterate over training dataset\n",
    "\n",
    "        # setup: batch generator, set loss and acc to 0, set train mode on\n",
    "\n",
    "        dataset.set_split('train')\n",
    "        batch_generator = generate_batches(dataset, \n",
    "                                           batch_size=args.batch_size, \n",
    "                                           device=args.device)\n",
    "        running_loss = 0.0\n",
    "        running_acc = 0.0\n",
    "        classifier.train()\n",
    "\n",
    "        for batch_index, batch_dict in enumerate(batch_generator):\n",
    "            # the training routine is these 5 steps:\n",
    "\n",
    "            # --------------------------------------\n",
    "            # step 1. zero the gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # step 2. compute the output\n",
    "            y_pred = classifier(batch_dict['x_surname'])         # (batch, input_dim) -> (batch, output_dim)\n",
    "\n",
    "            # step 3. compute the loss\n",
    "            loss = loss_func(y_pred, batch_dict['y_nationality'])  # (batch, output_dim), (batch) -> scalar value\n",
    "            loss_t = loss.item()\n",
    "            running_loss += (loss_t - running_loss) / (batch_index + 1)\n",
    "\n",
    "            # step 4. use loss to produce gradients\n",
    "            loss.backward()\n",
    "\n",
    "            # step 5. use optimizer to take gradient step\n",
    "            optimizer.step()\n",
    "            # -----------------------------------------\n",
    "            # compute the accuracy\n",
    "            acc_t = compute_accuracy(y_pred, batch_dict['y_nationality'])\n",
    "            running_acc += (acc_t - running_acc) / (batch_index + 1)\n",
    "\n",
    "            # update bar\n",
    "            train_bar.set_postfix(loss=running_loss, acc=running_acc, \n",
    "                            epoch=epoch_index)\n",
    "            train_bar.update()\n",
    "\n",
    "        train_state['train_loss'].append(running_loss)\n",
    "        train_state['train_acc'].append(running_acc)\n",
    "\n",
    "        # Iterate over val dataset\n",
    "\n",
    "        # setup: batch generator, set loss and acc to 0; set eval mode on\n",
    "        dataset.set_split('val')\n",
    "        batch_generator = generate_batches(dataset, \n",
    "                                           batch_size=args.batch_size, \n",
    "                                           device=args.device)\n",
    "        running_loss = 0.\n",
    "        running_acc = 0.\n",
    "        classifier.eval()\n",
    "\n",
    "        for batch_index, batch_dict in enumerate(batch_generator):\n",
    "\n",
    "            # compute the output\n",
    "            y_pred =  classifier(batch_dict['x_surname'])\n",
    "\n",
    "            # step 3. compute the loss\n",
    "            loss = loss_func(y_pred, batch_dict['y_nationality'])\n",
    "            loss_t = loss.to(\"cpu\").item()\n",
    "            running_loss += (loss_t - running_loss) / (batch_index + 1)\n",
    "\n",
    "            # compute the accuracy\n",
    "            acc_t = compute_accuracy(y_pred, batch_dict['y_nationality'])\n",
    "            running_acc += (acc_t - running_acc) / (batch_index + 1)\n",
    "            val_bar.set_postfix(loss=running_loss, acc=running_acc, \n",
    "                            epoch=epoch_index)\n",
    "            val_bar.update()\n",
    "\n",
    "        train_state['val_loss'].append(running_loss)\n",
    "        train_state['val_acc'].append(running_acc)\n",
    "\n",
    "        train_state = update_train_state(args=args, model=classifier,\n",
    "                                         train_state=train_state)\n",
    "\n",
    "        scheduler.step(train_state['val_loss'][-1])\n",
    "\n",
    "        if train_state['stop_early']:\n",
    "            break\n",
    "\n",
    "        train_bar.n = 1\n",
    "        val_bar.n = 1\n",
    "        epoch_bar.update()\n",
    "except KeyboardInterrupt:\n",
    "    print(\"Exiting loop\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "acc = train_state['train_acc']\n",
    "val_acc = train_state['val_acc']\n",
    "loss = train_state['train_loss']\n",
    "val_loss = train_state['val_loss']\n",
    "\n",
    "epochs = range(1, len(acc) + 1)\n",
    "\n",
    "# \"bo\" is for \"blue dot\"\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "# b is for \"solid blue line\"\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX4AAAEWCAYAAABhffzLAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAgAElEQVR4nO3dd3hUZfbA8e8RkN4EVIoQsC8hgRhBF7CB2MWChYUVVOQna8G6sjZYFQsW1NVVUUR2zaKsiqir2OvaCAIBxBXUgBGkSRWkhPP7472TTMIkmYS5c6ecz/PMMzN37r1zZgLnvvPe955XVBVjjDHpY4+gAzDGGBNflviNMSbNWOI3xpg0Y4nfGGPSjCV+Y4xJM5b4jTEmzVjiNwCISC0R2SQi7WO5bpBE5AARifl4ZRHpKyKFYc//JyK9o1m3Bu/1lIjcWNPtjYmkdtABmJoRkU1hTxsAW4Fi7/n/qWpedfanqsVAo1ivmw5U9eBY7EdEhgGDVfWYsH0Pi8W+jQlniT9JqWpJ4vValMNU9Z2K1heR2qq6Ix6xGVMV+/cYLOvqSVEicoeIPC8iU0RkIzBYRI4Ukc9FZJ2ILBeRh0Wkjrd+bRFREcnwnj/rvf6GiGwUkc9EpGN11/VeP0lEvhWR9SLyNxH5r4gMrSDuaGL8PxFZLCJrReThsG1rich4EVkjIt8BJ1by/dwsIs+VW/aoiDzgPR4mIgu9z/Od1xqvaF9FInKM97iBiPzTi20BcFiE9/3e2+8CETndW94FeATo7XWjrQ77bseEbX+p99nXiMjLItI6mu+mOt9zKB4ReUdEfhGRn0Xkz2Hvc4v3nWwQkXwRaROpW01EPgn9nb3v8yPvfX4BbhaRA0Xkfe+zrPa+t6Zh23fwPuMq7/WHRKSeF/OhYeu1FpHNItKios9rylFVuyX5DSgE+pZbdgewDTgNd4CvDxwO9MD90usEfAtc7q1fG1Agw3v+LLAayAXqAM8Dz9Zg3b2BjUB/77VrgO3A0Ao+SzQxTgeaAhnAL6HPDlwOLADaAS2Aj9w/8Yjv0wnYBDQM2/dKINd7fpq3jgDHAVuALO+1vkBh2L6KgGO8x/cBHwDNgQ7A1+XWPRdo7f1N/uDFsI/32jDgg3JxPguM8R7382LsCtQD/g68F813U83vuSmwAhgJ1AWaAN291/4CzAUO9D5DV2Av4IDy3zXwSejv7H22HcAIoBbu3+NBQB9gT+/fyX+B+8I+z3zv+2zord/Te20CMDbsfa4FpgX9/zCZboEHYLcY/BErTvzvVbHddcC/vceRkvnjYeueDsyvwboXAR+HvSbAcipI/FHGeETY6y8B13mPP8J1eYVeO7l8Miq378+BP3iPTwK+rWTd14DLvMeVJf6l4X8L4E/h60bY73zgFO9xVYl/MnBn2GtNcOd12lX13VTze/4jkF/Bet+F4i23PJrE/30VMQwAZnqPewM/A7UirNcT+AEQ7/kc4KxY/79K5Zt19aS2H8OfiMghIvIf76f7BuA2oGUl2/8c9ngzlZ/QrWjdNuFxqPufWlTRTqKMMar3ApZUEi/Av4CB3uM/ACUnxEXkVBH5wuvqWIdrbVf2XYW0riwGERkqInO97op1wCFR7hfc5yvZn6puANYCbcPWiepvVsX3vB+wuIIY9sMl/5oo/+9xXxGZKiI/eTE8Uy6GQnUDCcpQ1f/ifj30EpFMoD3wnxrGlJYs8ae28kMZn8C1MA9Q1SbArbgWuJ+W41qkAIiIUDZRlbc7MS7HJYyQqoabPg/0FZF2uK6of3kx1gdeAO7CdcM0A96KMo6fK4pBRDoBj+G6O1p4+/0mbL9VDT1dhus+Cu2vMa5L6aco4iqvsu/5R2D/Crar6LVfvZgahC3bt9w65T/fPbjRaF28GIaWi6GDiNSqII5/AINxv06mqurWCtYzEVjiTy+NgfXAr97Jsf+Lw3u+BuSIyGkiUhvXb9zKpxinAleJSFvvRN8Nla2sqitw3RGTgP+p6iLvpbq4fudVQLGInIrri442hhtFpJm46xwuD3utES75rcIdA4fhWvwhK4B24SdZy5kCXCwiWSJSF3dg+lhVK/wFVYnKvudXgPYicrmI7CkiTUSku/faU8AdIrK/OF1FZC/cAe9n3CCCWiIynLCDVCUx/AqsF5H9cN1NIZ8Ba4A7xZ0wry8iPcNe/yeua+gPuIOAqQZL/OnlWmAI7mTrE7gWr6+85Hoe8ADuP/L+wGxcSy/WMT4GvAvMA2biWu1V+Reuz/5fYTGvA64GpuFOkA7AHcCiMRr3y6MQeIOwpKSqBcDDwJfeOocAX4Rt+zawCFghIuFdNqHtZ+C6ZKZ527cHBkUZV3kVfs+quh44HjgbdzL5W+Bo7+V7gZdx3/MG3InWel4X3iXAjbgT/QeU+2yRjAa64w5ArwAvhsWwAzgVOBTX+l+K+zuEXi/E/Z23qeqn1fzsaS90csSYuPB+ui8DBqjqx0HHY5KXiPwDd8J4TNCxJBu7gMv4TkROxP10/w03HHAHrtVrTI1450v6A12CjiUZWVePiYdewPe4LoATgTPsZJypKRG5C3ctwZ2qujToeJKRdfUYY0yasRa/McakmaTo42/ZsqVmZGQEHYYxxiSVWbNmrVbVXYZPJ0Xiz8jIID8/P+gwjDEmqYhIxKvXravHGGPSjCV+Y4xJM5b4jTEmzSRFH38k27dvp6ioiN9++y3oUEwl6tWrR7t27ahTp6LyM8aYeEvaxF9UVETjxo3JyMjAFXw0iUZVWbNmDUVFRXTs2LHqDYwxcZG0XT2//fYbLVq0sKSfwESEFi1a2K8yY2ogLw8yMmCPPdx9Xl5VW0QvaVv8gCX9JGB/I2OqLy8Phg+HzZvd8yVL3HOAQTWtxxomaVv8xhiTqm66qTTph2ze7JbHgiX+GlqzZg1du3ala9eu7LvvvrRt27bk+bZt26Lax4UXXsj//ve/Std59NFHyYvlbzxjTMJbWkHpuYqWV1dSd/VUR16eO1ouXQrt28PYsbv3k6lFixbMmTMHgDFjxtCoUSOuu+66MuuUTGy8R+Tj66RJk6p8n8suu6zmQRpjklL79q57J9LyWEiLFn+ov2zJElAt7S/zoyG9ePFiMjMzufTSS8nJyWH58uUMHz6c3NxcOnfuzG233Vaybq9evZgzZw47duygWbNmjBo1iuzsbI488khWrlwJwM0338yDDz5Ysv6oUaPo3r07Bx98MJ9+6iYe+vXXXzn77LPJzs5m4MCB5ObmlhyUwo0ePZrDDz+8JL5QZdZvv/2W4447juzsbHJycigsLATgzjvvpEuXLmRnZ3NTrH5jGmOqNHYsNGhQdlmDBm55LKRF4ve7v6y8r7/+mosvvpjZs2fTtm1b7r77bvLz85k7dy5vv/02X3/99S7brF+/nqOPPpq5c+dy5JFH8vTTT0fct6ry5Zdfcu+995YcRP72t7+x7777MnfuXEaNGsXs2bMjbjty5EhmzpzJvHnzWL9+PTNmzABg4MCBXH311cydO5dPP/2Uvffem1dffZU33niDL7/8krlz53LttdfG6NsxxlRl0CCYMAE6dAARdz9hQmxO7EKaJH6/+8vK23///Tn88MNLnk+ZMoWcnBxycnJYuHBhxMRfv359TjrpJAAOO+ywklZ3eWedddYu63zyySecf/75AGRnZ9O5c+eI27777rt0796d7OxsPvzwQxYsWMDatWtZvXo1p512GuAuuGrQoAHvvPMOF110EfXr1wdgr732qv4XYYypsUGDoLAQdu5097FK+pAmffx+95eV17Bhw5LHixYt4qGHHuLLL7+kWbNmDB48OOK49j333LPkca1atdixY0fEfdetW3eXdaKZTGfz5s1cfvnlfPXVV7Rt25abb765JI5IQy5V1YZiGpOi0qLF73d/WWU2bNhA48aNadKkCcuXL+fNN9+M+Xv06tWLqVOnAjBv3ryIvyi2bNnCHnvsQcuWLdm4cSMvvvgiAM2bN6dly5a8+uqrgLswbvPmzfTr14+JEyeyZcsWAH755ZeYx22MCUZaJH6/+8sqk5OTw+9+9zsyMzO55JJL6NmzZ8zf44orruCnn34iKyuL+++/n8zMTJo2bVpmnRYtWjBkyBAyMzM588wz6dGjR8lreXl53H///WRlZdGrVy9WrVrFqaeeyoknnkhubi5du3Zl/PjxMY/bGBOMpJhzNzc3V8tPxLJw4UIOPfTQgCJKLDt27GDHjh3Uq1ePRYsW0a9fPxYtWkTt2onRk2d/K2OCISKzVDW3/HJfM4OINAOeAjIBBS4CTgAuAVZ5q92oqq/7GUeq27RpE3369GHHjh2oKk888UTCJH1jTOLxOzs8BMxQ1QEisifQAJf4x6vqfT6/d9po1qwZs2bNCjoMY0yS8C3xi0gT4ChgKICqbgO22UgRY4wJlp8ndzvhunMmichsEXlKRELjHC8XkQIReVpEmkfaWESGi0i+iOSvWrUq0irGGGNqwM/EXxvIAR5T1W7Ar8Ao4DFgf6ArsBy4P9LGqjpBVXNVNbdVq1Y+hmmMMenFz8RfBBSp6hfe8xeAHFVdoarFqroTeBLo7mMMxhhTLX5OgJIofEv8qvoz8KOIHOwt6gN8LSKtw1Y7E5jvVwx+OuaYY3a5GOvBBx/kT3/6U6XbNWrUCIBly5YxYMCACvddfvhqeQ8++CCbwwoQnXzyyaxbty6a0I0xFYhnQccg+X0B1xVAnogU4Lp27gTGicg8b9mxwNU+x+CLgQMH8txzz5VZ9txzzzFw4MCotm/Tpg0vvPBCjd+/fOJ//fXXadasWY33Z4yJf0HHoPia+FV1jtdPn6WqZ6jqWlX9o6p28ZadrqrL/YzBLwMGDOC1115j69atABQWFrJs2TJ69epVMq4+JyeHLl26MH369F22LywsJDMzE3DlFM4//3yysrI477zzSsokAIwYMaKkpPPo0aMBePjhh1m2bBnHHnssxx57LAAZGRmsXr0agAceeIDMzEwyMzNLSjoXFhZy6KGHcskll9C5c2f69etX5n1CXn31VXr06EG3bt3o27cvK1asANy1AhdeeCFdunQhKyurpOTDjBkzyMnJITs7mz59+sTkuzXpKRG6WOJd0DEoKXGVz1VXQYTy87ula1fwcmZELVq0oHv37syYMYP+/fvz3HPPcd555yEi1KtXj2nTptGkSRNWr17NEUccwemnn15h0bPHHnuMBg0aUFBQQEFBATk5OSWvjR07lr322ovi4mL69OlDQUEBV155JQ888ADvv/8+LVu2LLOvWbNmMWnSJL744gtUlR49enD00UfTvHlzFi1axJQpU3jyySc599xzefHFFxk8eHCZ7Xv16sXnn3+OiPDUU08xbtw47r//fm6//XaaNm3KvHnzAFi7di2rVq3ikksu4aOPPqJjx45Wz8fUmN9zzEYr3gUdg5IWtXr8Et7dE97No6rceOONZGVl0bdvX3766aeSlnMkH330UUkCzsrKIisrq+S1qVOnkpOTQ7du3ViwYEHEAmzhPvnkE84880waNmxIo0aNOOuss/j4448B6NixI127dgUqLv1cVFTECSecQJcuXbj33ntZsGABAO+8806Z2cCaN2/O559/zlFHHUXHjh0BK91sai5RuliCLOgYTynR4q+sZe6nM844g2uuuYavvvqKLVu2lLTU8/LyWLVqFbNmzaJOnTpkZGRELMUcLtKvgR9++IH77ruPmTNn0rx5c4YOHVrlfiqrvRQq6QyurHOkrp4rrriCa665htNPP50PPviAMWPGlOy3fIxWutnESqJ0sYR+XcRymtZEZC3+3dCoUSOOOeYYLrroojInddevX8/ee+9NnTp1eP/991kS6bdjmKOOOqpkQvX58+dTUFAAuJLODRs2pGnTpqxYsYI33nijZJvGjRuzcePGiPt6+eWX2bx5M7/++ivTpk2jd+/eUX+m9evX07ZtWwAmT55csrxfv3488sgjJc/Xrl3LkUceyYcffsgPP/wAWOlmU3MVdaUE0cXi5wQoicIS/24aOHAgc+fOLZkBC2DQoEHk5+eTm5tLXl4ehxxySKX7GDFiBJs2bSIrK4tx48bRvbu7tCE7O5tu3brRuXNnLrroojIlnYcPH85JJ51UcnI3JCcnh6FDh9K9e3d69OjBsGHD6NatW9SfZ8yYMZxzzjn07t27zPmDm2++mbVr15KZmUl2djbvv/8+rVq1YsKECZx11llkZ2dz3nnnRf0+xoRLly6WRGFlmY3v7G+V2PLyEqNrI1HiSCWBlGU2xiS2RBlNE3o/S/TxYV09xqSxRBlNY+IrqRN/MnRTpTv7GyW2RBlNY+IraRN/vXr1WLNmjSWWBKaqrFmzhnr16gUdiqlAIo2mMfGTtH387dq1o6ioCKvVn9jq1atHu3btgg6jjDVr4K23ID8f2raFAw+EAw6ATp0g7FKHtDB2bNk+frDRNOkgaRN/nTp1Sq4YNaYyO3fCrFnwxhvu9uWXblmdOrB9e+l6e+zhWroHHFB6MEj1g0K6XLBkykra4ZzGVCbUqn/jDZgxA1atAhE4/HA46SR3y82Fdetg8WJYtKj0PnQLr3KdjgcFk/xsOKdJaRW16lu2hBNOcIm+Xz8oP5lbixbu1qPHrvtcsybyQWHKlOgOCgceCB072kHBJB5L/CZpVdaqv+WW0lZ9rVo1278dFEyqssRvksbOnfDVV/D669Vr1fshlgeFo4+GCRNgzz39j9sYsMRvElx4q/7NN2Hlyti26v1QnYPCggUweTLstx/cfnv8YzXpyRK/SSihVv0bb7iWfahV36KFa9WffHL8WvV+iHRQGDIE7roLTjsNvPp8xvjKRvWYwFXWqg8fgZNIrfpYWrcOunSBhg1h9myoXz/oiEyqsFE9JmGkequ+upo1g0mT4Pjj4cYbYfz4oCMyqc4Sv4mrn3+Gnj3h++8Tv68+nvr2hcsuc7PJ9e8PxxwTdEQmlVniN3F1112u9O+kSXDKKenTqo/GPfe4rq6hQ6GgAJo0CToik6qStkibST5FRfD44y6xDR1qSb+8hg3dCJ8ff4Rrrgk6GpPKLPGbuBk7FlRd146J7Pe/h+uvh4kT4T//CToak6p8Tfwi0kxEXhCRb0RkoYgcKSJ7icjbIrLIu2/uZwwmMRQWumQ2bBh06BB0NIntr391o3yGDXMjnoyJNb9b/A8BM1T1ECAbWAiMAt5V1QOBd73nJsXdfru7UtVmdqpa3brwj3+4pH/ZZUFHY1KRb4lfRJoARwETAVR1m6quA/oDk73VJgNn+BWDSQyLF7u+6xEjXP174+TlQUaGOyBmZLjnIV27wujR8Pzz7mZMLPl2AZeIdAUmAF/jWvuzgJHAT6raLGy9taq6S3ePiAwHhgO0b9/+sCVLlvgSp/HfH/8IL73khnDus0/Q0SSG8pOcg5sAZcKE0lr4O3a4oa+LF8P8+dC6dTCxmuRV0QVcfnb11AZygMdUtRvwK9Xo1lHVCaqaq6q5rWz4R9L6+muX5C6/3JJ+uGgmOa9d2/1S2rwZLrnEnRg3Jhb8TPxFQJGqfuE9fwF3IFghIq0BvPuVPsZgAjZmjBumeP31QUeSWKKd5PyQQ+Duu90In6ef9j8ukx58S/yq+jPwo4gc7C3qg+v2eQUY4i0bAkz3KwYTrLlz4d//hquucqWTTanqTHJ+xRVw7LHueyws9DUskyb8HtVzBZAnIgVAV+BO4G7geBFZBBzvPTcpaPRoaNrULkaKZOxY16cfrqJJzvfYw13pLOIufNu5My4hmhTma+JX1TleP32Wqp6hqmtVdY2q9lHVA737X/yMwQQjPx+mT4drr4XmdqXGLgYNcidyO3RwCb1Dh7Indsvr0MHV8fnwQ3j44fjGalKPXblrfHHrrbDXXjByZNCR7KqyYZTxNGiQ67rZudPdV5T0Qy680NU3+stf4Jtv4hGhSVWW+E3MffaZK7l8ww2JV2gsNIxyyRI3SmbJEvc8qORfHSLw5JOuS2jIEDfc05iasMRvYu6WW2DvvRPzqtNohlEmstat4bHH3BwGd9vZMVNDlvhNTH3wAbz7ruuOaNgw6Gh2Fe0wykR27rlw/vmups/s2UFHY5KRJX4TM6HKm23awKWXBh1NZNUZRpnIHn3UDZG94ALYujXoaEwsqcK337qihkOHwnffxf49LPGbmHn7bfjkE9dtUq9e0NFEVp1hlIlsr71cYpg/3w2bNclrxw6YNQseeggGDIB994WDD3bVWf/zH1fqJNZssnUTE6pwxBFuasVvv3UVJhNVXp47OC1d6lr6Y8dWPaImUV1yibui9+OPXS3/ZDZ/vqvrtGIFdOvmCtV16+ZunTq5k9upYMsWd47m44/d7bPPYONG91qHDtC7d+ntkEN273NXVKvHEr+Jiddeg9NOc6NOhg0LOpr0sXEjZGW5uYrnzk3M8yrRCFVvbdrUTTo/Z46r81Rc7F5v0sQdCMIPBr/7HdSpE2zc0Vi3Dv7739JEn58P27a51zIzXYLv1cvd77dfbN/bEr/xjSocdhisX+/GlyfDf8ZU8uGHrqTDiBGu7z+ZbNniSlJMnOgmmJ8yxXV1APz2m/sVMHu2OxDMnu0ObqFRWXvu6RJn+MEgOxsaNQrs4wCwbFlpkv/4Y5g3z/0fqV0bcnNLW/M9e7ouOz9Z4je+eeklOPts12q74IKgo0lP11wD48fDW2+5FnMyWLQIzjnHJfMbb3SjlGrXrnyb4mK3XehAELqtXu1eF4EDDig9EIRue+/tz2dQdfGEJ/pQn3zDhnDkkaWJvkePXc8v+c0Sv/HFzp2ulbV9OyxY4LocTPxt2QI5Oa7rZ/58aNas6m2C9OKL7krkOnXgn/+Ek0+u+b5U4aefdj0YhBe0a9267IGga9eanTcoLnYHqlCS/+QTd04C3CirUJdN797uPYL+9VtR4q/i+GpM5aZOdYnmuecs6Qepfn03XeORR7oyGZMnV71NELZtc1d0P/igawFPnbr7Q2lFoF07dzv11NLla9e6JB1+MHjzzV3PG4QfDMqfN/jtt7InYj/9tOyJ2OOPj92J2HiyFr+psR07XB/rnnu61tYeNjg4cLfe6uY3njYNzkiwSU1//NFdfPb553DllXDvve7fTjxt2eJ+mYYfDAoKdj1vkJnpxs/PnFl6IrZz57IjbmJ9ItYP1tVjYm7yZHeByUsvwZlnBh2NAZekjjgCiorcLzG/+rara8YMGDzYxTdxouvbTxSh8wbhB4P588sOrezZE1q0CDrS6rPEb2Jq+3b307ZZMzc8LVl+4qaD+fPdKKtTTnF96UH+bYqL3SxsY8dCly5uYp6DDgounnQTxJy7JoU984wbvXDbbZb0E01mJtxxh+vuefbZ4OJYsQL69XOxXHih6+KxpJ8YrMVvqm3rVjjwQFeT57PPLPEnouJiOPpo1/qfP9+d+Iynjz5yheTWrYO//911CZr4sxa/iZmnnnIn6m6/3ZJ+oqpVy/0q274dLr7YDXmMh5074Z574LjjoHFj+OILS/qJyBK/qZYtW1x/be/e0Ldv0NGYyhxwANx3n7uo6/HH/X+/X36B/v1h1Ch3Qd/Mma5f3yQeS/ymWh5/HJYvt9Z+srj0UtfPft11sHixf+8zc6a7gOzNN+Fvf3PXdSTa7GumlCV+E7VNm9ysT336uP5jk/hE3PDJOnVcl0vo4qVYUXX1gXr1co8/+QQuv9waBYnOEr+J2iOPwMqVrrVfU4ky0Xk6adfOtcL/+1944IHY7XfjRvjDH1yiP/54N/69e/fY7d/4xxK/icqGDe5Ky5NPdmUBaiKZJzpPdoMHu4vsbr7ZjfLZXfPnw+GHu5ILd90Fr7zif6VJEzuW+E1UHnzQnby77baa7yPZJzpPZiLwxBOu3v0FF5SWIaiJyZNdy379enjvPXcy18p1JBdf/1wiUigi80Rkjojke8vGiMhP3rI5IrIbdflMPKxd67oIzjjDXRFaU6kw0Xkya9UKJkxwXTJ33FH97bdscZPsDB3qCqzNnm3nepJVPI7Tx6pq13IXEYz3lnVV1dfjEIPZDfff71p3f/3r7u0nVSY6T2ZnnOFa/Hfe6UbiRGvRItfFN3Giq53/9tulE6aY5GM/0EylVq92k0Cfe66b4m93pMpE58nuoYdcffoLLnCt+Kq8+KL7pffjj27y77Fjq54wxSQ2vxO/Am+JyCwRGR62/HIRKRCRp0WkeaQNRWS4iOSLSP6qVat8DtNUZNw41w8/Zszu72vQINfV0KGD63Pu0ME9T9aJzpNVs2ZugvZvvqn8/Mq2bXD11TBgABx6KHz11e5NmGISiKpWegMuB5pXtV4F27bx7vcG5gJHAfsAtXAHnbHA01Xt57DDDlMTf8uXq9avrzp4cNCRGD/86U+qIqoffLDra0uXqh5xhCqoXnGF6tat8Y/P7D4gXyPk1Gha/PsCM0VkqoicKBL9pRmqusy7XwlMA7qr6gpVLVbVncCTgI38TVB33eVafaNHBx2J8cO4cbD//u5kbWhWKXC187t1cxOWTJ0KDz8c/wlTjL+qTPyqejNwIDARGAosEpE7RWT/yrYTkYYi0jj0GOgHzBeR1mGrnQnEYFSxibWiIleeYcgQV/PFpJ6GDd3QzKVL3WTtxcVwyy2uO6dNGzfPQiJNmGJiJ6pTNKqqIvIz8DOwA2gOvCAib6vqnyvYbB9gmvcDoTbwL1WdISL/FJGuuP7/QuD/dvMzGB+MHesusrrllqAjMX76/e9dHZ9x41yinzPH1c5/5JFdT8Sb1FFlPX4RuRIYAqwGngJeVtXtIrIHsEhVK235x4LV44+vwkI3YcawYa6WukltW7e6q3AXLXJ/7wsvDDoiEysV1eOPpsXfEjhLVZeEL1TVnSJyagXbmCR2++3uSky7ojY91K0LH34Iv/4a/wlbTDCiObn7OvBL6ImINBaRHgCqutCvwEwwFi92/b6XXgpt2wYdjYmX5s0t6aeTaBL/Y8CmsOe/estMCvrrX90IjlGjgo7EGOOXaBK/aNiJAG8Ypl23l4IWLnSVMi+/3C7HNyaVRZP4vxeRK0WkjncbCXzvd2Am/saMcUP8/lzROC1jTEqIJvFfCvwe+D9PbTsAABDSSURBVAkoAnoAwyvdwiSduXPdxTojR0LLlkFHY4zxU5VdNt5Vt+fHIRYToNGjXa32a68NOhJjjN+qTPwiUg+4GOgM1AstV9WLfIzLxFF+Pkyf7iZZaR6xZJ4xJpVE09XzT1y9nhOAD4F2wMZKtzAJp7K5bm+91U2bN3JkUNEZY+IpmtE5B6jqOSLSX1Uni8i/gDf9DszETmiu29C0h6G5bgE6dYI33oC774YmTYKL0RgTP9Ek/u3e/ToRycTV68nwLSITc5XNdXvAAbD33m4IpzEmPUST+Cd4k6XcDLwCNAKsdFcSqWhO2yVL3O2BB9wwTmNMeqg08XuF2Dao6lrgI6BTXKIyMdW+vUvw5dWtCy1auPIMxpj0UenJXe8qXesESHKR5rqtW9dVZbzxRqhfP5i4jDHBiKar520RuQ54HlenBwBV/aXiTUwiCc1pe9NNrttnv/2gTh03u9awYcHGZoyJv2gSf2i8/mVhyxTr9kkqgwaVHgBeew1OO81NdF63brBxGWPiL5ordzvGIxATH6pu3H6nTm6uVWNM+onmyt0LIi1X1X/EPhzjt2nTYPZsV3O/Tp2gozHGBCGarp7Dwx7XA/oAXwGW+JPMzp2uJs/BB5d2+xhj0k80XT1XhD8Xkaa4Mg4myUydCvPnw5QpUKtW0NEYY4JSkwlVNgMHxjoQE1s7d7pJ0wsKYN48d//ee5CZCeeeG3R0xpggRdPH/ypuFA+4cf+/A6b6GZSpnnXrSpN7KNHPmwebvAkzRWD//eHoo+GWW1yhNmNM+oqmxX9f2OMdwBJVLfIpHlOJ7dvh22/LtuILCuDHH0vXad4csrLgwgvdfZcu0LkzNGoUXNzGmMQSTeJfCixX1d8ARKS+iGSoaqGvkaUxVfj557LJvaDAzYm7bZtbp3ZtOPRQ6N3bJfjQrU0b18I3xpiKRJP4/42bejGk2Ft2eOTVS4lIIa52fzGwQ1VzRWQv3FXAGUAhcK5XCygtbd4MX39dtpumoABWry5dp00bl9RPOKG0FX/IIbDnnsHFbYxJXtEk/tqqui30RFW3iUh1Us6xqhqWxhgFvKuqd4vIKO/5DdXYX1KKdLK1oAAWLXItfHD1dDIzoX//0hZ8ly6ukJoxxsRKNIl/lYicrqqvAIhIf2B1FdtUpj9wjPd4MvABKZ74b70Vxo8ve7K1UyeX2AcOLE3wnTrZMEtjjP9EQ83NilYQ2R/IA9p4i4qAC1R1cZU7F/kBWIsbFfSEqk4QkXWq2ixsnbWqustMryIyHBgO0L59+8OWRKornAS++w4OOgj69oUBA1ySt5Otxph4EJFZqppbfnk0F3B9BxwhIo1wB4rqzLfbU1WXicjeuCqf30S7oapOACYA5ObmVn50SmD33+9OxD7zDLRuHXQ0xhgTxWTrInKniDRT1U2qulFEmovIHdHsXFWXefcrgWlAd2CFiLT29t0aWFnz8BPbihXw9NMwZIglfWNM4ojmUp6TVHVd6Ik3AufkqjYSkYYi0jj0GOgHzMdN3zjEW20IML26QSeLhx92wy+vvz7oSIwxplQ0J3driUhdVd0Kbhw/EE0V932AaeIGldcG/qWqM0RkJjBVRC7GXSNwTs1CT2wbNsCjj8LZZ8OBVuDCGJNAokn8zwLvisgk7/mFuNE4lVLV74HsCMvX4Cp8prQJE2D9erghpccrGWOSUTQnd8eJSAHQFxBgBtDB78CS2dat8MAD0KcP5O5yPt0YY4IVbXXOn4GdwLnAD8CLvkWUAp59FpYvh3/YjAXGmARUYeIXkYOA84GBwBpcmQVR1WPjFFtSKi6GceMgJ8e1+I0xJtFU1uL/BvgYOC10sZaIXB2XqJLY9Omugubzz1uxNGNMYqpsOOfZuC6e90XkSRHpg+vjNxVQhbvvdrXvzz476GiMMSayChO/qk5T1fOAQ3D1dK4G9hGRx0SkX5ziSyoffAAzZ7px+1ZzxxiTqKq8gEtVf1XVPFU9FWgHzMFV1DTl3HMP7LOPu1I3JC8PMjLcrFcZGe65McYEqVqT8KnqL6r6hKoe51dAyWr2bHjzTbjqKqhXzy3Ly4Phw2HJEtcNtGSJe27J3xgTJJt9NUbGjYMmTWDEiNJlN93kJloJt3mzW26MMUGxxB8D330HU6fCpZdC06aly5cujbx+RcuNMSYeLPHHQKj08lVXlV3evn3k9Stabowx8WCJfzdVVnp57Fg3nWK4Bg3ccmOMCYol/t0UKr183XW7vjZokCvW1qGDu5irQwf3fNCg+MdpjDEhVU69mAhyc3M1Pz8/6DB2sWGD67Y5/nj497+DjsYYY8qqaOpFa/HvBiu9bIxJRpb4a8hKLxtjklW0ZZlNOaHSy5OrnJLGGGMSi7X4a6C4GO6915Ve7ts36GiMMaZ6rMVfA9Onw//+Z6WXjTHJyVr81aTqirFZ6WVjTLKyFn81ffABfPklPP64lV42xiQna/FXU6TSy8YYk0ws8VdDpNLLxhiTbCzxV8O4cdC4savCaYwxycr3xC8itURktoi85j1/RkR+EJE53q2r3zHEQqj08ogR0KxZ0NEYY0zNxePk7khgIdAkbNn1qvpCHN47ZioqvWyMMcnG1xa/iLQDTgGe8vN9/FZZ6WVjjEk2fnf1PAj8GdhZbvlYESkQkfEiUjfShiIyXETyRSR/1apVPodZucpKLxtjTLLxLfGLyKnASlWdVe6lvwCHAIcDewERa1uq6gRVzVXV3FatWvkVZpU2bIC//91drHXQQYGFYYwxMeNni78ncLqIFALPAceJyLOqulydrcAkoLuPMey2CRNg3TorvWyMSR2+JX5V/YuqtlPVDOB84D1VHSwirQFERIAzgPl+xbC7tm6F8eOt9LIxJrUEUbIhT0RaAQLMARJ2VPyzz8KyZfDMM0FHYowxsWNTL1aguBg6d3aTo8+aZVU4jTHJp6KpF61IWwWs9LIxJlVZyYYIrPSyMSaVWYs/Aiu9bIxJZdbij8BKLxtjUpkl/nKs9LIxJtVZ4i/HSi8bY1KdJf4wVnrZGJMOLPGHsdLLxph0YInfs2IFTJoEF1xgpZeNManNEr/n4YddbZ7rrw86EmOM8ZclfkpLL591lpVeNsakPkv8WOllY0x6SfvEHyq9fNxxcPjhQUdjjDH+S/uSDVZ62RiTbtK6xV9cDPfeC926Qd++QUdjjDHxkdYtfiu9bIxJR2nb4rfSy8aYdJW2LX4rvWyMSVdp2+K30svGmHSVlol/zhxXennkSCu9bIxJP2mZ+O+5x5VeHjEi6EiMMSb+0i7xf/+9K7186aVWetkYk57SLvHfd5+VXjbGpLe0SvzhpZfbtAk6GmOMCYbviV9EaonIbBF5zXveUUS+EJFFIvK8iOzpdwwhVnrZGGPi0+IfCSwMe34PMF5VDwTWAhfHIQYrvWyMMR5fE7+ItANOAZ7yngtwHPCCt8pk4Aw/Ywix0svGGOP43eJ/EPgzsNN73gJYp6o7vOdFQNtIG4rIcBHJF5H8VatW7VYQVnrZGGNK+Zb4ReRUYKWqzgpfHGFVjbS9qk5Q1VxVzW3VqtVuxRIqvWytfWOM8bdWT0/gdBE5GagHNMH9AmgmIrW9Vn87YJmPMbBzZ2np5eOP9/OdjDEmOfjW4lfVv6hqO1XNAM4H3lPVQcD7wABvtSHAdL9igNLSyzfcYKWXjTEGghnHfwNwjYgsxvX5T/TrjVTh7rut9LIxxoSLS1lmVf0A+MB7/D3QPR7v++GHrvTyY4+5q3WNMcak+JW7Tz/tSi8PHRp0JMYYkzhSuh08cSJ8+62VXjbGmHAp3eKvUwc6dw46CmOMSSwpnfiNMcbsyhK/McakGUv8xhiTZizxG2NMmrHEb4wxacYSvzHGpBlL/MYYk2Ys8RtjTJqxxG+MMWkmZRN/Xh5kZMAee7j7vLygIzLGmMSQkrV68vJg+HDYvNk9X7LEPQcYNCi4uIwxJhGkZIv/pptKk37I5s1uuTHGpLuUTPxLl1ZvuTHGpJOUTPzt21dvuTHGpJOUTPxjx0KDBmWXNWjglhtjTLpLycQ/aBBMmAAdOrgJ1jt0cM/txK4xxqToqB5wSd4SvTHG7ColW/zGGGMqZonfGGPSjCV+Y4xJM5b4jTEmzVjiN8aYNCOqGnQMVRKRVcCSoOPYTS2B1UEHkUDs+yhl30VZ9n2UtTvfRwdVbVV+YVIk/lQgIvmqmht0HInCvo9S9l2UZd9HWX58H9bVY4wxacYSvzHGpBlL/PEzIegAEox9H6XsuyjLvo+yYv59WB+/McakGWvxG2NMmrHEb4wxacYSv89EZD8ReV9EForIAhEZGXRMQRORWiIyW0ReCzqWoIlIMxF5QUS+8f6NHBl0TEERkau9/yPzRWSKiNQLOqZ4EpGnRWSliMwPW7aXiLwtIou8++axeC9L/P7bAVyrqocCRwCXicjvAo4paCOBhUEHkSAeAmao6iFANmn6vYhIW+BKIFdVM4FawPnBRhV3zwAnlls2CnhXVQ8E3vWe7zZL/D5T1eWq+pX3eCPuP3bbYKMKjoi0A04Bngo6lqCJSBPgKGAigKpuU9V1wUYVqNpAfRGpDTQAlgUcT1yp6kfAL+UW9wcme48nA2fE4r0s8ceRiGQA3YAvgo0kUA8CfwZ2Bh1IAugErAImeV1fT4lIw6CDCoKq/gTcBywFlgPrVfWtYKNKCPuo6nJwjUhg71js1BJ/nIhII+BF4CpV3RB0PEEQkVOBlao6K+hYEkRtIAd4TFW7Ab8So5/yycbru+4PdATaAA1FZHCwUaUuS/xxICJ1cEk/T1VfCjqeAPUETheRQuA54DgReTbYkAJVBBSpaugX4Au4A0E66gv8oKqrVHU78BLw+4BjSgQrRKQ1gHe/MhY7tcTvMxERXB/uQlV9IOh4gqSqf1HVdqqagTtx956qpm2rTlV/Bn4UkYO9RX2ArwMMKUhLgSNEpIH3f6YPaXqiu5xXgCHe4yHA9FjsNGUnW08gPYE/AvNEZI637EZVfT3AmEziuALIE5E9ge+BCwOOJxCq+oWIvAB8hRsJN5s0K90gIlOAY4CWIlIEjAbuBqaKyMW4g+M5MXkvK9lgjDHpxbp6jDEmzVjiN8aYNGOJ3xhj0owlfmOMSTOW+I0xJs1Y4jdpTUSKRWRO2C1mV86KSEZ4pUVjEoWN4zfpbouqdg06CGPiyVr8xkQgIoUico+IfOndDvCWdxCRd0WkwLtv7y3fR0Smichc7xYqN1BLRJ706sy/JSL1vfWvFJGvvf08F9DHNGnKEr9Jd/XLdfWcF/baBlXtDjyCqyqK9/gfqpoF5AEPe8sfBj5U1WxcvZ0F3vIDgUdVtTOwDjjbWz4K6Obt51K/PpwxkdiVuyaticgmVW0UYXkhcJyqfu8V2ftZVVuIyGqgtapu95YvV9WWIrIKaKeqW8P2kQG87U2igYjcANRR1TtEZAawCXgZeFlVN/n8UY0pYS1+YyqmFTyuaJ1ItoY9Lqb0vNopwKPAYcAsb/IRY+LCEr8xFTsv7P4z7/GnlE4JOAj4xHv8LjACSuYUblLRTkVkD2A/VX0fNylNM2CXXx3G+MVaGSbd1Q+rmgpu/tvQkM66IvIFroE00Ft2JfC0iFyPmz0rVE1zJDDBq6JYjDsILK/gPWsBz4pIU0CA8Wk+5aKJM+vjNyYCr48/V1VXBx2LMbFmXT3GGJNmrMVvjDFpxlr8xhiTZizxG2NMmrHEb4wxacYSvzHGpBlL/MYYk2b+H0JuxTpwMrG4AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.clf()   # clear figure\n",
    "\n",
    "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute the loss & accuracy on the test set using the best available model\n",
    "\n",
    "classifier.load_state_dict(torch.load(train_state['model_filename'])) # load the best model\n",
    "\n",
    "classifier = classifier.to(args.device)\n",
    "dataset.class_weights = dataset.class_weights.to(args.device)\n",
    "loss_func = nn.CrossEntropyLoss(dataset.class_weights)\n",
    "\n",
    "dataset.set_split('test')\n",
    "batch_generator = generate_batches(dataset, \n",
    "                                   batch_size=args.batch_size, \n",
    "                                   device=args.device)\n",
    "running_loss = 0.\n",
    "running_acc = 0.\n",
    "classifier.eval()\n",
    "\n",
    "y_pred_list = []         # store predicted values for confusion matrix\n",
    "y_nationality_list = []  # ground truth value\n",
    "\n",
    "for batch_index, batch_dict in enumerate(batch_generator):\n",
    "    # compute the output\n",
    "    y_pred =  classifier(batch_dict['x_surname'])\n",
    "    \n",
    "    # store predicted values and ground truth values for calculating confusion matrix\n",
    "    y_pred_list.extend(y_pred.max(dim=1)[1].numpy())\n",
    "    y_nationality_list.extend(batch_dict['y_nationality'].numpy())\n",
    "    \n",
    "    # compute the loss\n",
    "    loss = loss_func(y_pred, batch_dict['y_nationality'])\n",
    "    loss_t = loss.item()\n",
    "    running_loss += (loss_t - running_loss) / (batch_index + 1)\n",
    "\n",
    "    # compute the accuracy\n",
    "    acc_t = compute_accuracy(y_pred, batch_dict['y_nationality'])\n",
    "    running_acc += (acc_t - running_acc) / (batch_index + 1)\n",
    "\n",
    "train_state['test_loss'] = running_loss\n",
    "train_state['test_acc'] = running_acc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 1.6483283691177526;\n",
      "Test Accuracy: 64.69879518072277\n"
     ]
    }
   ],
   "source": [
    "print(\"Test loss: {};\".format(train_state['test_loss']))\n",
    "print(\"Test Accuracy: {}\".format(train_state['test_acc']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[224   1   2   3  12   1   1   0   2   5   3   0   0   0   6   0   1   0]\n",
      " [  0  17   1   0   4   0   2   0   0   0   0   6   0   0   4   1   1   2]\n",
      " [  0   0  12   2  26   0   5   0   0   0   2   0   4   1   5   1   0   0]\n",
      " [  0   0   3  13   7   0   3   0   0   0   0   1   0   0   5   0   1   0]\n",
      " [  0   7  17  11 306  13  32   7   8  11   2   2   1   1  22   8  10   4]\n",
      " [  0   0   1   1   1   5   0   0   0   1   0   0   0   0   3   0   0   0]\n",
      " [  0   0   3   0  13   1  26   0   0   1   0   0   1   0   4   0   2   0]\n",
      " [  0   0   1   0   0   0   0   9   0   1   0   0   0   0   0   0   0   0]\n",
      " [  4   0   0   1  10   1   1   0  13   3   2   0   0   1   2   2   0   0]\n",
      " [  3   3   3   3  40  10   6   1   3  49   4   0   2   2   6   0  11   2]\n",
      " [  8   2   5   0   3   2   4   3   1   2  99   1   1   0  10   0   1   0]\n",
      " [  0   3   0   0   0   0   0   0   0   0   2   3   0   0   0   0   0   1]\n",
      " [  0   0   1   0   0   0   0   0   0   1   0   0   4   0   0   0   0   0]\n",
      " [  0   0   1   0   5   0   0   1   1   5   1   0   0   1   1   0   7   0]\n",
      " [  2   0  13   2  18   2   4   3   0   8   1   0   4   0 289   0   1   0]\n",
      " [  0   0   0   0   2   0   1   0   0   1   0   0   0   0   0   0   1   0]\n",
      " [  0   0   0   0   0   0   2   0   0   2   1   0   1   3   0   0   4   1]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "print(confusion_matrix(y_nationality_list, y_pred_list).T)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Arabic', 'Chinese', 'Czech', 'Dutch', 'English', 'French', 'German', 'Greek', 'Irish', 'Italian', 'Japanese', 'Korean', 'Polish', 'Portuguese', 'Russian', 'Scottish', 'Spanish', 'Vietnamese']\n"
     ]
    }
   ],
   "source": [
    "nationality_classes = []\n",
    "for i in range(len(dataset._vectorizer.nationality_vocab)):\n",
    "    nationality_classes.append(dataset._vectorizer.nationality_vocab.lookup_index(i))\n",
    "print(nationality_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True        Arabic  Chinese  Czech  Dutch  English  French  German  Greek  \\\n",
      "Predicted                                                                   \n",
      "Arabic         224        1      2      3       12       1       1      0   \n",
      "Chinese          0       17      1      0        4       0       2      0   \n",
      "Czech            0        0     12      2       26       0       5      0   \n",
      "Dutch            0        0      3     13        7       0       3      0   \n",
      "English          0        7     17     11      306      13      32      7   \n",
      "French           0        0      1      1        1       5       0      0   \n",
      "German           0        0      3      0       13       1      26      0   \n",
      "Greek            0        0      1      0        0       0       0      9   \n",
      "Irish            4        0      0      1       10       1       1      0   \n",
      "Italian          3        3      3      3       40      10       6      1   \n",
      "Japanese         8        2      5      0        3       2       4      3   \n",
      "Korean           0        3      0      0        0       0       0      0   \n",
      "Polish           0        0      1      0        0       0       0      0   \n",
      "Portuguese       0        0      1      0        5       0       0      1   \n",
      "Russian          2        0     13      2       18       2       4      3   \n",
      "Scottish         0        0      0      0        2       0       1      0   \n",
      "Spanish          0        0      0      0        0       0       2      0   \n",
      "Vietnamese       0        0      0      0        0       0       0      0   \n",
      "\n",
      "True        Irish  Italian  Japanese  Korean  Polish  Portuguese  Russian  \\\n",
      "Predicted                                                                   \n",
      "Arabic          2        5         3       0       0           0        6   \n",
      "Chinese         0        0         0       6       0           0        4   \n",
      "Czech           0        0         2       0       4           1        5   \n",
      "Dutch           0        0         0       1       0           0        5   \n",
      "English         8       11         2       2       1           1       22   \n",
      "French          0        1         0       0       0           0        3   \n",
      "German          0        1         0       0       1           0        4   \n",
      "Greek           0        1         0       0       0           0        0   \n",
      "Irish          13        3         2       0       0           1        2   \n",
      "Italian         3       49         4       0       2           2        6   \n",
      "Japanese        1        2        99       1       1           0       10   \n",
      "Korean          0        0         2       3       0           0        0   \n",
      "Polish          0        1         0       0       4           0        0   \n",
      "Portuguese      1        5         1       0       0           1        1   \n",
      "Russian         0        8         1       0       4           0      289   \n",
      "Scottish        0        1         0       0       0           0        0   \n",
      "Spanish         0        2         1       0       1           3        0   \n",
      "Vietnamese      0        0         0       0       0           0        0   \n",
      "\n",
      "True        Scottish  Spanish  Vietnamese  \n",
      "Predicted                                  \n",
      "Arabic             0        1           0  \n",
      "Chinese            1        1           2  \n",
      "Czech              1        0           0  \n",
      "Dutch              0        1           0  \n",
      "English            8       10           4  \n",
      "French             0        0           0  \n",
      "German             0        2           0  \n",
      "Greek              0        0           0  \n",
      "Irish              2        0           0  \n",
      "Italian            0       11           2  \n",
      "Japanese           0        1           0  \n",
      "Korean             0        0           1  \n",
      "Polish             0        0           0  \n",
      "Portuguese         0        7           0  \n",
      "Russian            0        1           0  \n",
      "Scottish           0        1           0  \n",
      "Spanish            0        4           1  \n",
      "Vietnamese         0        0           0  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "cm = confusion_matrix(y_nationality_list, y_pred_list)\n",
    "cm_df = pd.DataFrame(cm.T, index=nationality_classes, columns=nationality_classes)\n",
    "cm_df.index.name = 'Predicted'\n",
    "cm_df.columns.name = 'True'\n",
    "print(cm_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.93      0.89       241\n",
      "           1       0.45      0.52      0.48        33\n",
      "           2       0.21      0.19      0.20        63\n",
      "           3       0.39      0.36      0.38        36\n",
      "           4       0.66      0.68      0.67       447\n",
      "           5       0.42      0.14      0.21        35\n",
      "           6       0.51      0.30      0.38        87\n",
      "           7       0.82      0.38      0.51        24\n",
      "           8       0.33      0.46      0.38        28\n",
      "           9       0.33      0.54      0.41        90\n",
      "          10       0.70      0.85      0.76       117\n",
      "          11       0.33      0.23      0.27        13\n",
      "          12       0.67      0.22      0.33        18\n",
      "          13       0.04      0.11      0.06         9\n",
      "          14       0.83      0.81      0.82       357\n",
      "          15       0.00      0.00      0.00        12\n",
      "          16       0.29      0.10      0.15        40\n",
      "          17       0.00      0.00      0.00        10\n",
      "\n",
      "    accuracy                           0.65      1660\n",
      "   macro avg       0.43      0.38      0.38      1660\n",
      "weighted avg       0.64      0.65      0.64      1660\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Gerald\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_nationality_list, y_pred_list))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "138px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": "5",
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
