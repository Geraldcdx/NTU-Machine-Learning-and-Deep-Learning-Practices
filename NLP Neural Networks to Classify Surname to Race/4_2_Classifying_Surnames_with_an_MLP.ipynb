{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 4. Classifying Surnames with a Multilayer Perceptron"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "from argparse import Namespace\n",
    "from collections import Counter\n",
    "import json\n",
    "import os\n",
    "import string\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Vectorization classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "class Vocabulary(object):\n",
    "    \"\"\"Class to process text and extract vocabulary for mapping\"\"\"\n",
    "\n",
    "    def __init__(self, token_to_idx=None, add_unk=True, unk_token=\"<UNK>\", mask_token=\"<MASK>\"):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            token_to_idx (dict): a pre-existing map of tokens to indices\n",
    "            add_unk (bool): a flag that indicates whether to add the UNK token\n",
    "            unk_token (str): the UNK token to add into the Vocabulary\n",
    "        \"\"\"\n",
    "\n",
    "        if token_to_idx is None:\n",
    "            token_to_idx = {}\n",
    "        self._token_to_idx = token_to_idx         # _token_to_idx: {''@'':0, 'a':1, 'b':2, ....., 'Á': 76}\n",
    "                                                  # _idx_to_token: {0:''@'', 1:'a', 2:'b', ....., 76:'Á'}\n",
    "            \n",
    "                                                  # _token_to_idx: {'Arabic': 0, 'Chinese': 1, ..., 'Vietnamese': 17}\n",
    "                                                  # _idx_to_token: {0:'Arabic',  1:'Chinese', ...,  17:'Vietnamese'}\n",
    "  \n",
    "        self._idx_to_token = {idx: token\n",
    "                              for token, idx in self._token_to_idx.items()}\n",
    "        self._mask_token = mask_token\n",
    "        self._add_unk = add_unk\n",
    "        self._unk_token = unk_token\n",
    "        \n",
    "        \n",
    "        self.unk_index = -1\n",
    "        if add_unk:\n",
    "            self.unk_index = self.add_token(unk_token) \n",
    "            self.mask_index = self.add_token(self._mask_token)  # mask_index set to 0\n",
    "               \n",
    "    def add_token(self, token):\n",
    "        \"\"\"Update mapping dicts based on the token.\n",
    "\n",
    "        Args:\n",
    "            token (str): the item to add into the Vocabulary\n",
    "        Returns:\n",
    "            index (int): the integer corresponding to the token\n",
    "        \"\"\"\n",
    "        token = token\n",
    "        try:\n",
    "            index = self._token_to_idx[token]\n",
    "        except KeyError:\n",
    "            index = len(self._token_to_idx)\n",
    "            self._token_to_idx[token] = index\n",
    "            self._idx_to_token[index] = token\n",
    "        return index\n",
    "    \n",
    "    def lookup_token(self, token):\n",
    "        \"\"\"Retrieve the index associated with the token \n",
    "          or the UNK index if token isn't present.\n",
    "        \n",
    "        Args:\n",
    "            token (str): the token to look up \n",
    "        Returns:\n",
    "            index (int): the index corresponding to the token\n",
    "        Notes:\n",
    "            `unk_index` needs to be >=0 (having been added into the Vocabulary) \n",
    "              for the UNK functionality \n",
    "        \"\"\"\n",
    "        token = token\n",
    "        if self.unk_index >= 0:\n",
    "            return self._token_to_idx.get(token, self.unk_index)\n",
    "        else:\n",
    "            return self._token_to_idx[token]\n",
    "\n",
    "    def lookup_index(self, index):\n",
    "        \"\"\"Return the token associated with the index\n",
    "        \n",
    "        Args: \n",
    "            index (int): the index to look up\n",
    "        Returns:\n",
    "            token (str): the token corresponding to the index\n",
    "        Raises:\n",
    "            KeyError: if the index is not in the Vocabulary\n",
    "        \"\"\"\n",
    "        if index not in self._idx_to_token:\n",
    "            raise KeyError(\"the index (%d) is not in the Vocabulary\" % index)\n",
    "        return self._idx_to_token[index]\n",
    "\n",
    "    def __str__(self):\n",
    "        return \"<Vocabulary(size=%d)>\" % len(self)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self._token_to_idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SurnameVectorizer(object):\n",
    "    \"\"\" The Vectorizer which coordinates the Vocabularies and puts them to use\"\"\"\n",
    "    def __init__(self, surname_vocab, nationality_vocab):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            surname_vocab (Vocabulary): maps characters to integers\n",
    "            nationality_vocab (Vocabulary): maps nationalities to integers\n",
    "        \"\"\"\n",
    "        self.surname_vocab = surname_vocab           # _token_to_idx: {'@':0, 'a':1, 'b':2, ....., 'Á': 76}\n",
    "        self.nationality_vocab = nationality_vocab     # _token_to_idx: {'Arabic': 0, 'Chinese': 1, ..., 'Vietnamese': 17}\n",
    "\n",
    "    def vectorize(self, surname, vector_length=-1):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            surname (str): the surname\n",
    "\n",
    "        Returns:\n",
    "            one_hot (np.ndarray): a collapsed one-hot encoding \n",
    "        \"\"\"\n",
    "        #split the individual characters\n",
    "        indices = [self.surname_vocab.lookup_token(char) for char in surname]\n",
    "        if vector_length < 0:\n",
    "            vector_length = len(indices)\n",
    "        out_vector = np.zeros(vector_length, dtype=np.int64)\n",
    "        out_vector[:len(indices)] = indices     # e.g., \"frankenstein , or the prometheus by mary wolls\" -> [3, 5, 9, 3, .., 35]\n",
    "        out_vector[len(indices):] = self.surname_vocab.mask_index # padding,                                                       # [3, 5, 9, 3, .., 35] -> [3, 5, 9, 3, .., 35, 0, 0, 0, 0]\n",
    "        return out_vector\n",
    "#         vocab = self.surname_vocab\n",
    "#         one_hot = np.zeros(len(vocab), dtype=np.float32)  # in this dataset, vector size is 77.\n",
    "#         for token in surname:\n",
    "#             one_hot[vocab.lookup_token(token)] = 1        # e.g., kim -> [0, 0, 0, 1, 0, 0, 1, 0, 0, 1, ......, 0]\n",
    "#         self.x = one_hot\n",
    "#         return one_hot\n",
    "\n",
    "    @classmethod\n",
    "    def from_dataframe(cls, surname_df):\n",
    "        \"\"\"Instantiate the vectorizer from the dataset dataframe\n",
    "        \n",
    "        Args:\n",
    "            surname_df (pandas.DataFrame): the surnames dataset\n",
    "        Returns:\n",
    "            an instance of the SurnameVectorizer\n",
    "        \"\"\"\n",
    "        surname_vocab = Vocabulary(unk_token=\"@\")\n",
    "        nationality_vocab = Vocabulary(add_unk=False)\n",
    "\n",
    "        for index, row in surname_df.iterrows():\n",
    "            for letter in row.surname:\n",
    "                surname_vocab.add_token(letter)   # token is letter-level.\n",
    "            nationality_vocab.add_token(row.nationality)\n",
    "        \n",
    "        return cls(surname_vocab, nationality_vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SurnameDataset(Dataset):\n",
    "    def __init__(self, surname_df, vectorizer):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            surname_df (pandas.DataFrame): the dataset\n",
    "            vectorizer (SurnameVectorizer): vectorizer instatiated from dataset\n",
    "        \"\"\"\n",
    "        self.surname_df = surname_df\n",
    "        self._vectorizer = vectorizer\n",
    "\n",
    "        measure_len = lambda surname: len(surname)\n",
    "        self._max_seq_length = max(map(measure_len, surname_df.surname))  \n",
    "        \n",
    "        self.train_df = self.surname_df[self.surname_df.split=='train']\n",
    "        self.train_size = len(self.train_df)\n",
    "\n",
    "        self.val_df = self.surname_df[self.surname_df.split=='val']\n",
    "        self.validation_size = len(self.val_df)\n",
    "\n",
    "        self.test_df = self.surname_df[self.surname_df.split=='test']\n",
    "        self.test_size = len(self.test_df)\n",
    "\n",
    "        self._lookup_dict = {'train': (self.train_df, self.train_size),\n",
    "                             'val': (self.val_df, self.validation_size),\n",
    "                             'test': (self.test_df, self.test_size)}\n",
    "\n",
    "        self.set_split('train')\n",
    "        \n",
    "        # Class weights for handling unbalanced data\n",
    "        class_counts = surname_df.nationality.value_counts().to_dict() # {'English': 2972, 'Russian': 2373, ....}\n",
    "        \n",
    "        def sort_key(item):\n",
    "            return self._vectorizer.nationality_vocab.lookup_token(item[0]) # e.g, index of English is 4\n",
    "        sorted_counts = sorted(class_counts.items(), key=sort_key)   # sort by the index number of nationality_vocab\n",
    "                                # {('Arabic', 1603), ('Chinese', 220), ('Czech', 414), ('Dutch', 236),('English', 2972), ...}\n",
    "\n",
    "        frequencies = [count for _, count in sorted_counts]\n",
    "        self.class_weights = 1.0 / torch.tensor(frequencies, dtype=torch.float32) \n",
    "                                                                     # [1/1603, 1/220, 1/414, 1/236, 1/2972, ...]\n",
    "                                                                     # E.g., penalty for Chinese is higher than one for Arabic.\n",
    "    @classmethod\n",
    "    def load_dataset_and_make_vectorizer(cls, surname_csv):\n",
    "        \"\"\"Load dataset and make a new vectorizer from scratch\n",
    "        \n",
    "        Args:\n",
    "            surname_csv (str): location of the dataset\n",
    "        Returns:\n",
    "            an instance of SurnameDataset\n",
    "        \"\"\"\n",
    "        surname_df = pd.read_csv(surname_csv)\n",
    "        train_surname_df = surname_df[surname_df.split=='train']\n",
    "        return cls(surname_df, SurnameVectorizer.from_dataframe(train_surname_df))\n",
    "\n",
    "    def get_vectorizer(self):\n",
    "        \"\"\" returns the vectorizer \"\"\"\n",
    "        return self._vectorizer\n",
    "\n",
    "    def set_split(self, split=\"train\"):\n",
    "        \"\"\" selects the splits in the dataset using a column in the dataframe \"\"\"\n",
    "        self._target_split = split\n",
    "        self._target_df, self._target_size = self._lookup_dict[split]\n",
    "\n",
    "    def __len__(self):\n",
    "        return self._target_size\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"the primary entry point method for PyTorch datasets\n",
    "        \n",
    "        Args:\n",
    "            index (int): the index to the data point \n",
    "        Returns:\n",
    "            a dictionary holding the data point's:\n",
    "                features (x_surname)\n",
    "                label (y_nationality)\n",
    "        \"\"\"\n",
    "        row = self._target_df.iloc[index]\n",
    "\n",
    "        surname_vector = \\\n",
    "            self._vectorizer.vectorize(row.surname, self._max_seq_length)   # e.g., 'kim' -> [0, 0, 0, 1, 0, 0, 1, 0, 0, 1, ......, 0]\n",
    "\n",
    "        nationality_index = \\\n",
    "            self._vectorizer.nationality_vocab.lookup_token(row.nationality)  # e.g., 'Korean' -> 11\n",
    "\n",
    "        return {'x_surname': surname_vector,\n",
    "                'y_nationality': nationality_index}\n",
    "\n",
    "    def get_num_batches(self, batch_size):\n",
    "        \"\"\"Given a batch size, return the number of batches in the dataset\n",
    "        \n",
    "        Args:\n",
    "            batch_size (int)\n",
    "        Returns:\n",
    "            number of batches in the dataset\n",
    "        \"\"\"\n",
    "        return len(self) // batch_size\n",
    "\n",
    "    \n",
    "def generate_batches(dataset, batch_size, shuffle=True,\n",
    "                     drop_last=True, device=\"cpu\"): \n",
    "    \"\"\"\n",
    "    A generator function which wraps the PyTorch DataLoader. It will \n",
    "      ensure each tensor is on the write device location.\n",
    "    \"\"\"\n",
    "    dataloader = DataLoader(dataset=dataset, batch_size=batch_size,\n",
    "                            shuffle=shuffle, drop_last=drop_last)\n",
    "\n",
    "    for data_dict in dataloader: # {'x_surname': [[1,1,..,0,1], [0,0,...,1,0], ...], \n",
    "                                 #  'y_nationality': [4, 5, 10, ..., 14, 4]}\n",
    "        out_data_dict = {}\n",
    "        for name, tensor in data_dict.items():  # name: x_surname & y_nationality\n",
    "            out_data_dict[name] = data_dict[name].to(device)\n",
    "        yield out_data_dict  # return out_data_dict whenever this generator function is called"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Model: SurnameClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SurnameClassifier(nn.Module):\n",
    "    \"\"\" A 2-layer Multilayer Perceptron for classifying surnames \"\"\"\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim, embedding_size, padding_idx=0):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            input_dim (int): the size of the input vectors\n",
    "            hidden_dim (int): the output size of the first Linear layer\n",
    "            output_dim (int): the output size of the second Linear layer\n",
    "        \"\"\"\n",
    "        super(SurnameClassifier, self).__init__()\n",
    "        self.embedding =  nn.Embedding(num_embeddings=input_dim,   \n",
    "                                       embedding_dim=embedding_size,\n",
    "                                       padding_idx=padding_idx)\n",
    "        #hidden_dim = 25\n",
    "        self.fc1 = nn.Linear(in_features=embedding_size,           # Applies a linear transformation to the incoming data\n",
    "                             out_features=hidden_dim, bias = True)\n",
    "        #self.fc1 = nn.Linear(input_dim, hidden_dim)\n",
    "        self.fc2 = nn.Linear(in_features=hidden_dim, out_features = output_dim, bias = True)\n",
    "        #self.fc3 = nn.Linear(in_features=30, out_features = output_dim, bias = True)\n",
    "        \n",
    "        #self.bn1 = nn.BatchNorm1d(hidden_dim) # for batch norm, need to be defined for each layer\n",
    "        #self.bn2 = nn.BatchNorm1d(hidden_dim)\n",
    "        #self.bn3 = nn.BatchNorm1d(output_dim)\n",
    "        #self.dpout = nn.Dropout(p=0.001) # for drop out, p = probability of an element to be zeroed. Default: 0.5\n",
    "\n",
    "\n",
    "    def forward(self, x_in, apply_softmax=False):\n",
    "        \"\"\"The forward pass of the classifier\n",
    "        \n",
    "        Args:\n",
    "            x_in (torch.Tensor): an input data tensor. \n",
    "                x_in.shape should be (batch, input_dim)\n",
    "            apply_softmax (bool): a flag for the softmax activation\n",
    "                should be false if used with the Cross Entropy losses\n",
    "        Returns:\n",
    "            the resulting tensor. tensor.shape should be (batch, output_dim)\n",
    "        \"\"\"\n",
    "        x_embedded =  self.embedding(x_in)\n",
    "        x_embedded_sum = x_embedded.sum(dim=1)\n",
    "        #x_embedded_sum = self.dpout(x_embedded_sum)\n",
    "        x_in = x_embedded_sum\n",
    "        intermediate_vector = self.fc1(x_in)                         # (batch, input_dim) -> (batch, hidden_dim)\n",
    "        #intermediate_vector = self.bn1(intermediate_vector)          # batch norm\n",
    "        m = nn.LeakyReLU(0.1)\n",
    "        #intermediate_vector = self.dpout(intermediate_vector) \n",
    "        intermediate_vector = m(intermediate_vector)   \n",
    "        #intermediate_vector = F.relu(intermediate_vector)            # activation function\n",
    "        #intermediate_vector = self.bn2(intermediate_vector)          # batch norm\n",
    "               # dropout\n",
    "        \n",
    "        prediction_vector = self.fc2(intermediate_vector)\n",
    "        #intermediate_vector = self.bn3(intermediate_vector)          # batch norm\n",
    "        #prediction_vector = self.fc3(intermediate_vector)            # (batch, hidden_dim) -> (batch, output_dim)\n",
    "\n",
    "        if apply_softmax:\n",
    "            prediction_vector = F.softmax(prediction_vector, dim=1)  # (batch, output_dim)\n",
    "\n",
    "        return prediction_vector                                     # (batch, output_dim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Routine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def make_train_state(args):\n",
    "    return {'stop_early': False,\n",
    "            'early_stopping_step': 0,\n",
    "            'early_stopping_best_val': 1e8,\n",
    "            'learning_rate': args.learning_rate,\n",
    "            'epoch_index': 0,\n",
    "            'train_loss': [],\n",
    "            'train_acc': [],\n",
    "            'val_loss': [],\n",
    "            'val_acc': [],\n",
    "            'test_loss': -1,\n",
    "            'test_acc': -1,\n",
    "            'model_filename': args.model_state_file}\n",
    "\n",
    "def update_train_state(args, model, train_state):\n",
    "    \"\"\"Handle the training state updates.\n",
    "\n",
    "    Components:\n",
    "     - Early Stopping: Prevent overfitting.\n",
    "     - Model Checkpoint: Model is saved if the model is better\n",
    "\n",
    "    :param args: main arguments\n",
    "    :param model: model to train\n",
    "    :param train_state: a dictionary representing the training state values\n",
    "    :returns:\n",
    "        a new train_state\n",
    "    \"\"\"\n",
    "\n",
    "    # Save one model at least\n",
    "    if train_state['epoch_index'] == 0:\n",
    "        torch.save(model.state_dict(), train_state['model_filename'])\n",
    "        train_state['stop_early'] = False\n",
    "\n",
    "    # Save model if performance improved\n",
    "    elif train_state['epoch_index'] >= 1:\n",
    "        loss_tm1, loss_t = train_state['val_loss'][-2:]\n",
    "\n",
    "        # If loss worsened\n",
    "        if loss_t >= train_state['early_stopping_best_val']:\n",
    "            # Update step\n",
    "            train_state['early_stopping_step'] += 1\n",
    "        # Loss decreased\n",
    "        else:\n",
    "            # Save the best model\n",
    "            if loss_t < train_state['early_stopping_best_val']:\n",
    "                torch.save(model.state_dict(), train_state['model_filename'])\n",
    "                train_state['early_stopping_best_val'] = loss_t  # update 'early_stopping_best_val'\n",
    "\n",
    "            # Reset early stopping step\n",
    "            train_state['early_stopping_step'] = 0\n",
    "\n",
    "        # Stop early ?\n",
    "        train_state['stop_early'] = \\\n",
    "            train_state['early_stopping_step'] >= args.early_stopping_criteria\n",
    "\n",
    "    return train_state\n",
    "\n",
    "def compute_accuracy(y_pred, y_target):\n",
    "    _, y_pred_indices = y_pred.max(dim=1)\n",
    "    n_correct = torch.eq(y_pred_indices, y_target).sum().item()\n",
    "    return n_correct / len(y_pred_indices) * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### general utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed_everywhere(seed, cuda):\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if cuda:\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "def handle_dirs(dirpath):\n",
    "    if not os.path.exists(dirpath):\n",
    "        os.makedirs(dirpath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Settings and some prep work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expanded filepaths: \n",
      "\tmodel_storage/ch4/surname_mlp\\model.pth\n",
      "Using CUDA: False\n"
     ]
    }
   ],
   "source": [
    "args = Namespace(\n",
    "    # Data and path information\n",
    "    surname_csv=\"data/surnames/surnames_with_splits.csv\",\n",
    "    model_state_file=\"model.pth\",\n",
    "    save_dir=\"model_storage/ch4/surname_mlp\",\n",
    "    # Model hyper parameters\n",
    "    hidden_dim=1000,#300,\n",
    "    embedding_size=300, #was 50\n",
    "    # Training  hyper parameters\n",
    "    seed=1337,\n",
    "    num_epochs=25,#100,\n",
    "    early_stopping_criteria=5,\n",
    "    learning_rate=0.001,\n",
    "    batch_size= 2, #256,#was 64\n",
    "    # Runtime options\n",
    "    cuda=False,\n",
    "    expand_filepaths_to_save_dir=True,\n",
    ")\n",
    "\n",
    "if args.expand_filepaths_to_save_dir:\n",
    "    args.model_state_file = os.path.join(args.save_dir, args.model_state_file)   \n",
    "    print(\"Expanded filepaths: \")\n",
    "    print(\"\\t{}\".format(args.model_state_file))\n",
    "    \n",
    "# Check CUDA\n",
    "if not torch.cuda.is_available():\n",
    "    args.cuda = False\n",
    "\n",
    "args.device = torch.device(\"cuda\" if args.cuda else \"cpu\")\n",
    "    \n",
    "print(\"Using CUDA: {}\".format(args.cuda))\n",
    "\n",
    "\n",
    "# Set seed for reproducibility\n",
    "set_seed_everywhere(args.seed, args.cuda)\n",
    "\n",
    "# handle dirs\n",
    "handle_dirs(args.save_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initializations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating fresh!\n"
     ]
    }
   ],
   "source": [
    "# create dataset and vectorizer\n",
    "print(\"Creating fresh!\")\n",
    "dataset = SurnameDataset.load_dataset_and_make_vectorizer(args.surname_csv)\n",
    "    \n",
    "vectorizer = dataset.get_vectorizer()\n",
    "classifier = SurnameClassifier(input_dim=len(vectorizer.surname_vocab), \n",
    "                               hidden_dim=args.hidden_dim, \n",
    "                               output_dim=len(vectorizer.nationality_vocab),\n",
    "                               embedding_size=args.embedding_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 -> ('', SurnameClassifier(\n",
      "  (embedding): Embedding(80, 300, padding_idx=0)\n",
      "  (fc1): Linear(in_features=300, out_features=1000, bias=True)\n",
      "  (fc2): Linear(in_features=1000, out_features=18, bias=True)\n",
      "))\n",
      "1 -> ('embedding', Embedding(80, 300, padding_idx=0))\n",
      "2 -> ('fc1', Linear(in_features=300, out_features=1000, bias=True))\n",
      "3 -> ('fc2', Linear(in_features=1000, out_features=18, bias=True))\n"
     ]
    }
   ],
   "source": [
    "for idx, m in enumerate(classifier.named_modules()):\n",
    "        print(idx, '->', m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.nn.parameter.Parameter'> torch.Size([80, 300])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([1000, 300])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([1000])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([18, 1000])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([18])\n"
     ]
    }
   ],
   "source": [
    "for param in classifier.parameters():\n",
    "    print(type(param), param.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'@': 0,\n",
       " '<MASK>': 1,\n",
       " 'G': 2,\n",
       " 'a': 3,\n",
       " 'b': 4,\n",
       " 'e': 5,\n",
       " 'r': 6,\n",
       " 'S': 7,\n",
       " 'y': 8,\n",
       " 'g': 9,\n",
       " 'h': 10,\n",
       " 'K': 11,\n",
       " 'o': 12,\n",
       " 'u': 13,\n",
       " 'i': 14,\n",
       " 'I': 15,\n",
       " 's': 16,\n",
       " 'B': 17,\n",
       " 't': 18,\n",
       " 'T': 19,\n",
       " 'n': 20,\n",
       " 'H': 21,\n",
       " 'd': 22,\n",
       " 'A': 23,\n",
       " 'l': 24,\n",
       " 'm': 25,\n",
       " 'M': 26,\n",
       " 'f': 27,\n",
       " 'Z': 28,\n",
       " 'N': 29,\n",
       " 'k': 30,\n",
       " 'w': 31,\n",
       " 'W': 32,\n",
       " 'E': 33,\n",
       " 'c': 34,\n",
       " 'j': 35,\n",
       " 'Q': 36,\n",
       " 'D': 37,\n",
       " 'z': 38,\n",
       " 'F': 39,\n",
       " 'C': 40,\n",
       " 'R': 41,\n",
       " 'Y': 42,\n",
       " 'L': 43,\n",
       " 'J': 44,\n",
       " 'P': 45,\n",
       " 'X': 46,\n",
       " ':': 47,\n",
       " 'O': 48,\n",
       " '-': 49,\n",
       " 'p': 50,\n",
       " 'U': 51,\n",
       " 'v': 52,\n",
       " 'V': 53,\n",
       " '1': 54,\n",
       " 'x': 55,\n",
       " '/': 56,\n",
       " 'q': 57,\n",
       " 'é': 58,\n",
       " 'ê': 59,\n",
       " \"'\": 60,\n",
       " 'É': 61,\n",
       " 'ö': 62,\n",
       " 'ä': 63,\n",
       " 'ü': 64,\n",
       " 'ß': 65,\n",
       " 'ú': 66,\n",
       " 'à': 67,\n",
       " 'ò': 68,\n",
       " 'è': 69,\n",
       " 'ù': 70,\n",
       " 'ó': 71,\n",
       " 'ń': 72,\n",
       " 'Ś': 73,\n",
       " 'ą': 74,\n",
       " 'á': 75,\n",
       " 'Ż': 76,\n",
       " 'ã': 77,\n",
       " 'í': 78,\n",
       " 'ñ': 79}"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.surname_vocab._token_to_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Arabic': 0,\n",
       " 'Chinese': 1,\n",
       " 'Czech': 2,\n",
       " 'Dutch': 3,\n",
       " 'English': 4,\n",
       " 'French': 5,\n",
       " 'German': 6,\n",
       " 'Greek': 7,\n",
       " 'Irish': 8,\n",
       " 'Italian': 9,\n",
       " 'Japanese': 10,\n",
       " 'Korean': 11,\n",
       " 'Polish': 12,\n",
       " 'Portuguese': 13,\n",
       " 'Russian': 14,\n",
       " 'Scottish': 15,\n",
       " 'Spanish': 16,\n",
       " 'Vietnamese': 17}"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.nationality_vocab._token_to_idx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "910232b43edb48b09bdf6f96e323542d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='training routine', max=25.0, style=ProgressStyle(descript…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "13cdb3d2c74342a8aeb60703f793a98c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='split=train', max=3840.0, style=ProgressStyle(description…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9043d9cce6244ecf873d45de20ee2bf1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='split=val', max=820.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "classifier = classifier.to(args.device)\n",
    "dataset.class_weights = dataset.class_weights.to(args.device)\n",
    "\n",
    "    \n",
    "loss_func = nn.CrossEntropyLoss(dataset.class_weights)  # add class_weight for an unbalanced dataset\n",
    "optimizer = optim.Adam(classifier.parameters(), lr=args.learning_rate)\n",
    "#optimizer = optim.Adam(classifier.parameters(), lr=args.learning_rate, weight_decay=0.001) # weight_decay for L2 regularization\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer=optimizer, mode='min', factor=0.1, patience=10) # update learning rate\n",
    "\n",
    "train_state = make_train_state(args)\n",
    "\n",
    "epoch_bar = tqdm(desc='training routine', total=args.num_epochs, position=0)\n",
    "\n",
    "dataset.set_split('train')\n",
    "train_bar = tqdm(desc='split=train', total=dataset.get_num_batches(args.batch_size), position=1, leave=True)\n",
    "dataset.set_split('val')\n",
    "val_bar = tqdm(desc='split=val', total=dataset.get_num_batches(args.batch_size), position=1, leave=True)\n",
    "\n",
    "try:\n",
    "    for epoch_index in range(args.num_epochs):\n",
    "        train_state['epoch_index'] = epoch_index\n",
    "\n",
    "        # Iterate over training dataset\n",
    "\n",
    "        # setup: batch generator, set loss and acc to 0, set train mode on\n",
    "\n",
    "        dataset.set_split('train')\n",
    "        batch_generator = generate_batches(dataset, \n",
    "                                           batch_size=args.batch_size, \n",
    "                                           device=args.device)\n",
    "        running_loss = 0.0\n",
    "        running_acc = 0.0\n",
    "        classifier.train()\n",
    "\n",
    "        for batch_index, batch_dict in enumerate(batch_generator):\n",
    "            # the training routine is these 5 steps:\n",
    "\n",
    "            # --------------------------------------\n",
    "            # step 1. zero the gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # step 2. compute the output\n",
    "            y_pred = classifier(batch_dict['x_surname'])         # (batch, input_dim) -> (batch, output_dim)\n",
    "\n",
    "            # step 3. compute the loss\n",
    "            loss = loss_func(y_pred, batch_dict['y_nationality'])  # (batch, output_dim), (batch) -> scalar value\n",
    "            loss_t = loss.item()\n",
    "            running_loss += (loss_t - running_loss) / (batch_index + 1)\n",
    "\n",
    "            # step 4. use loss to produce gradients\n",
    "            loss.backward()\n",
    "\n",
    "            # step 5. use optimizer to take gradient step\n",
    "            optimizer.step()\n",
    "            # -----------------------------------------\n",
    "            # compute the accuracy\n",
    "            acc_t = compute_accuracy(y_pred, batch_dict['y_nationality'])\n",
    "            running_acc += (acc_t - running_acc) / (batch_index + 1)\n",
    "\n",
    "            # update bar\n",
    "            train_bar.set_postfix(loss=running_loss, acc=running_acc, \n",
    "                            epoch=epoch_index)\n",
    "            train_bar.update()\n",
    "\n",
    "        train_state['train_loss'].append(running_loss)\n",
    "        train_state['train_acc'].append(running_acc)\n",
    "\n",
    "        # Iterate over val dataset\n",
    "\n",
    "        # setup: batch generator, set loss and acc to 0; set eval mode on\n",
    "        dataset.set_split('val')\n",
    "        batch_generator = generate_batches(dataset, \n",
    "                                           batch_size=args.batch_size, \n",
    "                                           device=args.device)\n",
    "        running_loss = 0.\n",
    "        running_acc = 0.\n",
    "        classifier.eval()\n",
    "\n",
    "        for batch_index, batch_dict in enumerate(batch_generator):\n",
    "\n",
    "            # compute the output\n",
    "            y_pred =  classifier(batch_dict['x_surname'])\n",
    "\n",
    "            # step 3. compute the loss\n",
    "            loss = loss_func(y_pred, batch_dict['y_nationality'])\n",
    "            loss_t = loss.to(\"cpu\").item()\n",
    "            running_loss += (loss_t - running_loss) / (batch_index + 1)\n",
    "\n",
    "            # compute the accuracy\n",
    "            acc_t = compute_accuracy(y_pred, batch_dict['y_nationality'])\n",
    "            running_acc += (acc_t - running_acc) / (batch_index + 1)\n",
    "            val_bar.set_postfix(loss=running_loss, acc=running_acc, \n",
    "                            epoch=epoch_index)\n",
    "            val_bar.update()\n",
    "\n",
    "        train_state['val_loss'].append(running_loss)\n",
    "        train_state['val_acc'].append(running_acc)\n",
    "\n",
    "        train_state = update_train_state(args=args, model=classifier,\n",
    "                                         train_state=train_state)\n",
    "\n",
    "        scheduler.step(train_state['val_loss'][-1])\n",
    "\n",
    "        if train_state['stop_early']:\n",
    "            break\n",
    "\n",
    "        train_bar.n = 1\n",
    "        val_bar.n = 1\n",
    "        epoch_bar.update()\n",
    "except KeyboardInterrupt:\n",
    "    print(\"Exiting loop\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "acc = train_state['train_acc']\n",
    "val_acc = train_state['val_acc']\n",
    "loss = train_state['train_loss']\n",
    "val_loss = train_state['val_loss']\n",
    "\n",
    "epochs = range(1, len(acc) + 1)\n",
    "\n",
    "# \"bo\" is for \"blue dot\"\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "# b is for \"solid blue line\"\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.clf()   # clear figure\n",
    "\n",
    "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute the loss & accuracy on the test set using the best available model\n",
    "\n",
    "classifier.load_state_dict(torch.load(train_state['model_filename'])) # load the best model\n",
    "\n",
    "classifier = classifier.to(args.device)\n",
    "dataset.class_weights = dataset.class_weights.to(args.device)\n",
    "loss_func = nn.CrossEntropyLoss(dataset.class_weights)\n",
    "\n",
    "dataset.set_split('test')\n",
    "batch_generator = generate_batches(dataset, \n",
    "                                   batch_size=args.batch_size, \n",
    "                                   device=args.device)\n",
    "running_loss = 0.\n",
    "running_acc = 0.\n",
    "classifier.eval()\n",
    "\n",
    "y_pred_list = []         # store predicted values for confusion matrix\n",
    "y_nationality_list = []  # ground truth value\n",
    "\n",
    "for batch_index, batch_dict in enumerate(batch_generator):\n",
    "    # compute the output\n",
    "    y_pred =  classifier(batch_dict['x_surname'])\n",
    "    \n",
    "    # store predicted values and ground truth values for calculating confusion matrix\n",
    "    y_pred_list.extend(y_pred.max(dim=1)[1].numpy())\n",
    "    y_nationality_list.extend(batch_dict['y_nationality'].numpy())\n",
    "    \n",
    "    # compute the loss\n",
    "    loss = loss_func(y_pred, batch_dict['y_nationality'])\n",
    "    loss_t = loss.item()\n",
    "    running_loss += (loss_t - running_loss) / (batch_index + 1)\n",
    "\n",
    "    # compute the accuracy\n",
    "    acc_t = compute_accuracy(y_pred, batch_dict['y_nationality'])\n",
    "    running_acc += (acc_t - running_acc) / (batch_index + 1)\n",
    "\n",
    "train_state['test_loss'] = running_loss\n",
    "train_state['test_acc'] = running_acc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 1.8507144466313956;\n",
      "Test Accuracy: 59.337349397590366\n"
     ]
    }
   ],
   "source": [
    "print(\"Test loss: {};\".format(train_state['test_loss']))\n",
    "print(\"Test Accuracy: {}\".format(train_state['test_acc']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[223   0   3   1  17   1   1   1   3   9  13   0   0   1  11   0   0   0]\n",
      " [  0  14   0   0   4   0   1   0   0   0   1   2   0   0   2   1   0   4]\n",
      " [  0   0   8   3  11   0   6   1   0   2   4   0   1   0   5   0   0   0]\n",
      " [  0   0   2   8   2   0   2   0   0   0   0   0   0   0   2   0   1   0]\n",
      " [  4   1  17  11 264  13  23   1   8  17   3   1   1   1  21   7   9   2]\n",
      " [  0   1   1   1   4   3   0   3   0   1   1   0   0   0   2   0   2   0]\n",
      " [  0   1   4   8  33   4  29   0   0   4   1   0   1   0   2   3   5   2]\n",
      " [  2   0   2   0   2   1   0   7   1   2   2   0   0   0   2   0   0   0]\n",
      " [  0   1   0   0   3   1   1   0  10   1   1   1   0   0   1   0   0   0]\n",
      " [  0   1   1   0  12   1   1   1   1  21   1   0   1   0   2   0   2   0]\n",
      " [  5   1   3   0   9   1   2   2   1   1  76   0   1   0   5   0   2   0]\n",
      " [  0   4   1   0   1   0   0   0   0   0   0   6   0   0   0   0   1   1]\n",
      " [  0   1   4   0   3   0   5   0   0   1   1   1   5   0   1   0   0   0]\n",
      " [  0   0   1   0   2   3   0   2   0   1   2   0   1   1   1   0   1   0]\n",
      " [  4   7  14   1  59   2  13   2   2  13   8   2   5   0 295   1   3   0]\n",
      " [  0   0   0   0   2   0   0   0   0   0   0   0   1   0   0   0   0   0]\n",
      " [  3   1   2   3  18   5   3   4   2  17   3   0   1   6   5   0  14   0]\n",
      " [  0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0   1]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "print(confusion_matrix(y_nationality_list, y_pred_list).T)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Arabic', 'Chinese', 'Czech', 'Dutch', 'English', 'French', 'German', 'Greek', 'Irish', 'Italian', 'Japanese', 'Korean', 'Polish', 'Portuguese', 'Russian', 'Scottish', 'Spanish', 'Vietnamese']\n"
     ]
    }
   ],
   "source": [
    "nationality_classes = []\n",
    "for i in range(len(dataset._vectorizer.nationality_vocab)):\n",
    "    nationality_classes.append(dataset._vectorizer.nationality_vocab.lookup_index(i))\n",
    "print(nationality_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True        Arabic  Chinese  Czech  Dutch  English  French  German  Greek  \\\n",
      "Predicted                                                                   \n",
      "Arabic         223        0      3      1       17       1       1      1   \n",
      "Chinese          0       14      0      0        4       0       1      0   \n",
      "Czech            0        0      8      3       11       0       6      1   \n",
      "Dutch            0        0      2      8        2       0       2      0   \n",
      "English          4        1     17     11      264      13      23      1   \n",
      "French           0        1      1      1        4       3       0      3   \n",
      "German           0        1      4      8       33       4      29      0   \n",
      "Greek            2        0      2      0        2       1       0      7   \n",
      "Irish            0        1      0      0        3       1       1      0   \n",
      "Italian          0        1      1      0       12       1       1      1   \n",
      "Japanese         5        1      3      0        9       1       2      2   \n",
      "Korean           0        4      1      0        1       0       0      0   \n",
      "Polish           0        1      4      0        3       0       5      0   \n",
      "Portuguese       0        0      1      0        2       3       0      2   \n",
      "Russian          4        7     14      1       59       2      13      2   \n",
      "Scottish         0        0      0      0        2       0       0      0   \n",
      "Spanish          3        1      2      3       18       5       3      4   \n",
      "Vietnamese       0        0      0      0        1       0       0      0   \n",
      "\n",
      "True        Irish  Italian  Japanese  Korean  Polish  Portuguese  Russian  \\\n",
      "Predicted                                                                   \n",
      "Arabic          3        9        13       0       0           1       11   \n",
      "Chinese         0        0         1       2       0           0        2   \n",
      "Czech           0        2         4       0       1           0        5   \n",
      "Dutch           0        0         0       0       0           0        2   \n",
      "English         8       17         3       1       1           1       21   \n",
      "French          0        1         1       0       0           0        2   \n",
      "German          0        4         1       0       1           0        2   \n",
      "Greek           1        2         2       0       0           0        2   \n",
      "Irish          10        1         1       1       0           0        1   \n",
      "Italian         1       21         1       0       1           0        2   \n",
      "Japanese        1        1        76       0       1           0        5   \n",
      "Korean          0        0         0       6       0           0        0   \n",
      "Polish          0        1         1       1       5           0        1   \n",
      "Portuguese      0        1         2       0       1           1        1   \n",
      "Russian         2       13         8       2       5           0      295   \n",
      "Scottish        0        0         0       0       1           0        0   \n",
      "Spanish         2       17         3       0       1           6        5   \n",
      "Vietnamese      0        0         0       0       0           0        0   \n",
      "\n",
      "True        Scottish  Spanish  Vietnamese  \n",
      "Predicted                                  \n",
      "Arabic             0        0           0  \n",
      "Chinese            1        0           4  \n",
      "Czech              0        0           0  \n",
      "Dutch              0        1           0  \n",
      "English            7        9           2  \n",
      "French             0        2           0  \n",
      "German             3        5           2  \n",
      "Greek              0        0           0  \n",
      "Irish              0        0           0  \n",
      "Italian            0        2           0  \n",
      "Japanese           0        2           0  \n",
      "Korean             0        1           1  \n",
      "Polish             0        0           0  \n",
      "Portuguese         0        1           0  \n",
      "Russian            1        3           0  \n",
      "Scottish           0        0           0  \n",
      "Spanish            0       14           0  \n",
      "Vietnamese         0        0           1  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "cm = confusion_matrix(y_nationality_list, y_pred_list)\n",
    "cm_df = pd.DataFrame(cm.T, index=nationality_classes, columns=nationality_classes)\n",
    "cm_df.index.name = 'Predicted'\n",
    "cm_df.columns.name = 'True'\n",
    "print(cm_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.93      0.85       241\n",
      "           1       0.48      0.42      0.45        33\n",
      "           2       0.20      0.13      0.15        63\n",
      "           3       0.47      0.22      0.30        36\n",
      "           4       0.65      0.59      0.62       447\n",
      "           5       0.16      0.09      0.11        35\n",
      "           6       0.30      0.33      0.32        87\n",
      "           7       0.33      0.29      0.31        24\n",
      "           8       0.50      0.36      0.42        28\n",
      "           9       0.47      0.23      0.31        90\n",
      "          10       0.70      0.65      0.67       117\n",
      "          11       0.43      0.46      0.44        13\n",
      "          12       0.23      0.28      0.25        18\n",
      "          13       0.07      0.11      0.08         9\n",
      "          14       0.68      0.83      0.75       357\n",
      "          15       0.00      0.00      0.00        12\n",
      "          16       0.16      0.35      0.22        40\n",
      "          17       0.50      0.10      0.17        10\n",
      "\n",
      "    accuracy                           0.59      1660\n",
      "   macro avg       0.39      0.35      0.36      1660\n",
      "weighted avg       0.58      0.59      0.58      1660\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_nationality_list, y_pred_list))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "138px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": "5",
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
